{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModelsDir = '/home/kate/Research/Property/Models/'\n",
    "ModelName='wc_Poisson_f_ecy_XGB'\n",
    "UseSavedIfExists = True\n",
    "DataDir = '/home/kate/Research/Property/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/kate/code/Utils/')\n",
    "\n",
    "from MyFunctions import NormalizedWeightedGini\n",
    "from MyFunctions import nLogLik_XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataset = pd.read_csv('%sproperty_wcf_training.csv'%DataDir, error_bad_lines=False, index_col=False)\n",
    "testing_dataset = pd.read_csv('%sproperty_wcf_testing.csv'%DataDir, error_bad_lines=False, index_col=False)\n",
    "prediction_dataset = pd.read_csv('%sproperty_water_claims_non_cat_fs.csv'%DataDir, error_bad_lines=False, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_column = 'cova_ic_nc_water'\n",
    "prediction_column_cv='poisson_f_ecy_cv_xgb'\n",
    "prediction_column_fold = 'poisson_f_ecy_xgb_fold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureset  = [\n",
    "'roofcd_encd',\n",
    "'sqft',  \n",
    "'usagetype_encd',\n",
    "'yearbuilt',\n",
    "'water_risk_3_blk',\n",
    "'landlordind',\n",
    "'multipolicyind',    \n",
    "'cova_deductible',\n",
    "'cova_limit',\n",
    "'ecy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrounds=5000\n",
    "simon_params = {\n",
    "        'objective': 'count:poisson',\n",
    "        'eval_metric': 'poisson-nloglik',\n",
    "        'silent': True,\n",
    "        'booster': 'gbtree',\n",
    "        'eta': 0.01, \n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 3,\n",
    "        'max_depth': 6,\n",
    "        'gamma': 0,\n",
    "        'seed': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fold: 1  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_Poisson_f_ecy_XGB_0.model file exists. Reading model from the file\n",
      " fold: 2  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_Poisson_f_ecy_XGB_1.model file exists. Reading model from the file\n",
      " fold: 3  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_Poisson_f_ecy_XGB_2.model file exists. Reading model from the file\n",
      " fold: 4  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_Poisson_f_ecy_XGB_3.model file exists. Reading model from the file\n",
      " fold: 5  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_Poisson_f_ecy_XGB_4.model file exists. Reading model from the file\n"
     ]
    }
   ],
   "source": [
    "training_dataset[prediction_column_cv]=0\n",
    "for i in range(0,kfold):\n",
    "    training_dataset['%s_%s'%(prediction_column_fold,i)]=0\n",
    "#\n",
    "testing_dataset[prediction_column_cv]=0\n",
    "for i in range(0,kfold):\n",
    "    testing_dataset['%s_%s'%(prediction_column_fold,i)]=0\n",
    "#\n",
    "prediction_dataset[prediction_column_cv]=0\n",
    "for i in range(0,kfold):\n",
    "    prediction_dataset['%s_%s'%(prediction_column_fold,i)]=0\n",
    "#\n",
    "Train_Gini_l = list()\n",
    "Test_Gini_l = list()\n",
    "Train_LogLik_l = list()\n",
    "Test_LogLik_l = list()\n",
    "#preparing for XGB run\n",
    "#\n",
    "X=training_dataset[featureset]\n",
    "y=training_dataset[target_column]\n",
    "Dtrain = xgb.DMatrix(X.values,y)\n",
    "#\n",
    "X_test=testing_dataset[featureset]\n",
    "y_test=testing_dataset[target_column]\n",
    "Dtest = xgb.DMatrix(X_test.values)\n",
    "#\n",
    "X_pred=prediction_dataset[featureset]\n",
    "y_pred=prediction_dataset[target_column]\n",
    "Dpred = xgb.DMatrix(X_pred.values)\n",
    "#-----------------------------------------------------------------------------------------------------------       \n",
    "#CV-folds modeling\n",
    "for i in range(0,kfold):\n",
    "    print(' fold: {}  of  {} : '.format(i+1, kfold))\n",
    "    training_dataset_fold = training_dataset[training_dataset['fold_%s'%i]>0]\n",
    "    validation_dataset = training_dataset[training_dataset['fold_%s'%i]==0]\n",
    "        \n",
    "    X_train =  training_dataset_fold[featureset].copy()\n",
    "    X_valid =  validation_dataset[featureset].copy()        \n",
    "    y_train =  training_dataset_fold[target_column].copy()\n",
    "\n",
    "    y_valid =  validation_dataset[target_column].copy()       \n",
    "                \n",
    "  \n",
    "    #preparing for XGB run\n",
    "    X_train = X_train.values\n",
    "    X_valid = X_valid.values\n",
    "    #\n",
    "    y_pred_train=pd.DataFrame(index=y_train.index)\n",
    "    y_pred_train[prediction_column_cv]=0\n",
    "    #\n",
    "    y_train = y_train.values\n",
    "    y_valid = y_valid.values\n",
    "    #\n",
    "    #\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    #\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    #\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "    #applying XGB\n",
    "    xgb_model_file='%s%s_%s.model'%(ModelsDir,ModelName,i)\n",
    "    if (os.path.exists(xgb_model_file) & UseSavedIfExists):\n",
    "        print('%s file exists. Reading model from the file'%xgb_model_file)\n",
    "        xgb_model = pickle.load(open(xgb_model_file, 'rb'))\n",
    "    else:\n",
    "        print('%s file does not exists. Training model...'%xgb_model_file)\n",
    "        xgb_model = xgb.train(simon_params, d_train, nrounds, watchlist,   verbose_eval=100, early_stopping_rounds=100)\n",
    "        pickle.dump(xgb_model, open(xgb_model_file, 'wb'))\n",
    "            \n",
    "    pred = xgb_model.predict(Dtrain, ntree_limit=xgb_model.best_ntree_limit+50)\n",
    "    training_dataset[prediction_column_cv]+=   pred/ (kfold)\n",
    "    training_dataset['%s_%s'%(prediction_column_fold,i)]=  pred\n",
    "        \n",
    "    pred = xgb_model.predict(Dtest, ntree_limit=xgb_model.best_ntree_limit+50)\n",
    "    testing_dataset[prediction_column_cv] +=   pred/(kfold)  \n",
    "    testing_dataset['%s_%s'%(prediction_column_fold,i)] =  pred \n",
    "    \n",
    "    pred = xgb_model.predict(Dpred, ntree_limit=xgb_model.best_ntree_limit+50)\n",
    "    prediction_dataset[prediction_column_cv] +=   pred/(kfold)  \n",
    "    prediction_dataset['%s_%s'%(prediction_column_fold,i)] =  pred     \n",
    "\n",
    "#Scores cv folds\n",
    "Train_Gini_l.append(NormalizedWeightedGini(training_dataset[target_column],training_dataset[prediction_column_cv],training_dataset['ecy']))\n",
    "Test_Gini_l.append(NormalizedWeightedGini(testing_dataset[target_column],testing_dataset[prediction_column_cv],testing_dataset['ecy']))\n",
    "Train_LogLik_l.append(nLogLik_XGBoost(training_dataset[target_column],training_dataset[prediction_column_cv]))\n",
    "Test_LogLik_l.append(nLogLik_XGBoost(testing_dataset[target_column],testing_dataset[prediction_column_cv]))\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "#Saving training\n",
    "training_dataset.to_csv('%sproperty_wcf_training.csv'%DataDir,header=True,index=False)\n",
    "testing_dataset.to_csv('%sproperty_wcf_testing.csv'%DataDir,header=True,index=False)\n",
    "prediction_dataset.to_csv('%sproperty_water_claims_non_cat_fs.csv'%DataDir,header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Gini</th>\n",
       "      <th>Test_Gini</th>\n",
       "      <th>Train_nLogLik</th>\n",
       "      <th>Test_nLogLik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.489133</td>\n",
       "      <td>0.447039</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.038461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train_Gini  Test_Gini  Train_nLogLik  Test_nLogLik\n",
       "0    0.489133   0.447039       0.036308      0.038461"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores = pd.DataFrame(list(zip(Train_Gini_l,Test_Gini_l,Train_LogLik_l,Test_LogLik_l)), \n",
    "               columns =['Train_Gini', 'Test_Gini','Train_nLogLik', 'Test_nLogLik']) \n",
    "Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.50679\t0.436416\t0.060119\t0.03884"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
