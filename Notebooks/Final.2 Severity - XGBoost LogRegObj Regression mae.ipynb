{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModelsDir = '/home/kate/Research/Property/Models/'\n",
    "ModelName='wc_LogRegObj_Reg_XGB_mae'\n",
    "UseSavedIfExists = True\n",
    "DataDir = '/home/kate/Research/Property/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/kate/code/Utils/')\n",
    "\n",
    "from MyFunctions import NormalizedWeightedGini\n",
    "from MyFunctions import mae\n",
    "from MyFunctions import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataset = pd.read_csv('%sproperty_wcs_training_for_normal.csv'%DataDir, error_bad_lines=False, index_col=False)\n",
    "testing_dataset = pd.read_csv('%sproperty_wcf_testing.csv'%DataDir, error_bad_lines=False, index_col=False)\n",
    "prediction_dataset = pd.read_csv('%sproperty_water_claims_non_cat_fs.csv'%DataDir, error_bad_lines=False, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_column = 'log_cova_il_nc_water'\n",
    "prediction_column_cv='LogRegObj_reg_xgb_mae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=[\n",
    "'cova_deductible',\n",
    "'roofcd_encd',\n",
    "'water_risk_sev_3_blk',\n",
    "'sqft',\n",
    "'rep_cost_3_blk',\n",
    "'yearbuilt',\n",
    "'ecy',\n",
    "'usagetype_encd'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=training_dataset[features]\n",
    "y=training_dataset[target_column]\n",
    "Dtrain = xgb.DMatrix(X.values,y)\n",
    "#\n",
    "X_test=testing_dataset[features]\n",
    "y_test=testing_dataset[target_column]\n",
    "Dtest = xgb.DMatrix(X_test.values)\n",
    "#\n",
    "X_pred=prediction_dataset[features]\n",
    "y_pred=prediction_dataset[target_column]\n",
    "Dpred = xgb.DMatrix(X_pred.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrounds = 500\n",
    "esr=100\n",
    "kfold=5\n",
    "xgb_params = {\n",
    "    'seed': 42,\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 1, \n",
    "    'silent': 1,\n",
    "    'subsample': 1, \n",
    "    'max_depth': 6,\n",
    "    'gamma': 0.3, \n",
    "    'min_child_weight': 3 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    con = 2\n",
    "    x =preds-labels\n",
    "    grad =con*x / (np.abs(x)+con)\n",
    "    hess =con**2 / (np.abs(x)+con)**2\n",
    "    return grad, hess \n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fold: 1  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_LogRegObj_Reg_XGB_mae_0.model file exists. Reading model from the file\n",
      " fold: 2  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_LogRegObj_Reg_XGB_mae_1.model file exists. Reading model from the file\n",
      " fold: 3  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_LogRegObj_Reg_XGB_mae_2.model file exists. Reading model from the file\n",
      " fold: 4  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_LogRegObj_Reg_XGB_mae_3.model file exists. Reading model from the file\n",
      " fold: 5  of  5 : \n",
      "/home/kate/Research/Property/Models/wc_LogRegObj_Reg_XGB_mae_4.model file exists. Reading model from the file\n"
     ]
    }
   ],
   "source": [
    "training_dataset[prediction_column_cv] = 0\n",
    "testing_dataset[prediction_column_cv] = 0\n",
    "prediction_dataset[prediction_column_cv] = 0\n",
    "#\n",
    "trn_gini_l = list()\n",
    "trn_mae_l = list()\n",
    "trn_rmse_l = list()\n",
    "test_gini_l = list()\n",
    "test_mae_l = list()\n",
    "test_rmse_l = list()\n",
    "#\n",
    "for i in range(0,kfold):\n",
    "    print(' fold: {}  of  {} : '.format(i+1, kfold))\n",
    "    training_dataset_fold = training_dataset[training_dataset['fold_%s'%i]>0]\n",
    "    validation_dataset = training_dataset[training_dataset['fold_%s'%i]==0]\n",
    "        \n",
    "    X_train =  training_dataset_fold[features].copy()\n",
    "    X_valid =  validation_dataset[features].copy()        \n",
    "    y_train =  training_dataset_fold[target_column].copy()\n",
    "    y_valid =  validation_dataset[target_column].copy()       \n",
    "                \n",
    "  \n",
    "    #preparing for XGB run\n",
    "    X_train = X_train.values\n",
    "    X_valid = X_valid.values\n",
    "    #\n",
    "    y_pred_train=pd.DataFrame(index=y_train.index)\n",
    "    y_pred_train[prediction_column_cv]=0\n",
    "    #\n",
    "    y_train = y_train.values\n",
    "    y_valid = y_valid.values\n",
    "    #\n",
    "    #\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    #\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    #\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "    #applying XGB\n",
    "    xgb_model_file='%s%s_%s.model'%(ModelsDir,ModelName,i)\n",
    "    if (os.path.exists(xgb_model_file) & UseSavedIfExists):\n",
    "        print('%s file exists. Reading model from the file'%xgb_model_file)\n",
    "        xgb_model = pickle.load(open(xgb_model_file, 'rb'))\n",
    "    else:\n",
    "        print('%s file does not exists. Training model...'%xgb_model_file)\n",
    "        xgb_model = xgb.train(xgb_params, d_train, nrounds, watchlist,  obj=logregobj, feval=evalerror, verbose_eval=100, early_stopping_rounds=esr)\n",
    "        pickle.dump(xgb_model, open(xgb_model_file, 'wb'))\n",
    "    \n",
    "        \n",
    "    training_dataset[prediction_column_cv]+=  xgb_model.predict(Dtrain, ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)       \n",
    "    testing_dataset[prediction_column_cv] +=  xgb_model.predict(Dtest, ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
    "    prediction_dataset[prediction_column_cv] +=  xgb_model.predict(Dpred, ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataset[prediction_column_cv] = np.exp(training_dataset[prediction_column_cv])\n",
    "testing_dataset[prediction_column_cv] = np.exp(testing_dataset[prediction_column_cv])\n",
    "prediction_dataset[prediction_column_cv] = np.exp(prediction_dataset[prediction_column_cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_gini_l.append(NormalizedWeightedGini(np.exp(prediction_dataset[prediction_dataset.cal_year>2019][target_column]),prediction_dataset[prediction_dataset.cal_year>2019][prediction_column_cv],prediction_dataset[prediction_dataset.cal_year>2019]['cova_ic_nc_water']))\n",
    "trn_mae_l.append(mae(np.exp(training_dataset[target_column]),training_dataset[prediction_column_cv]))\n",
    "trn_rmse_l.append(rmse(np.exp(training_dataset[target_column]),training_dataset[prediction_column_cv]))\n",
    "    #\n",
    "test_gini_l.append(NormalizedWeightedGini(np.exp(testing_dataset[target_column]),testing_dataset[prediction_column_cv],testing_dataset.cova_ic_nc_water))\n",
    "test_mae_l.append(mae(np.exp(testing_dataset[testing_dataset.cova_ic_nc_water>0][target_column]),testing_dataset[testing_dataset.cova_ic_nc_water>0][prediction_column_cv]))\n",
    "test_rmse_l.append(rmse(np.exp(testing_dataset[testing_dataset.cova_ic_nc_water>0][target_column]),testing_dataset[testing_dataset.cova_ic_nc_water>0][prediction_column_cv]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trn_gini</th>\n",
       "      <th>trn_mae</th>\n",
       "      <th>trn_rmse</th>\n",
       "      <th>test_gini</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.29784</td>\n",
       "      <td>9674.240242</td>\n",
       "      <td>22346.456421</td>\n",
       "      <td>0.284799</td>\n",
       "      <td>11245.016619</td>\n",
       "      <td>22120.953015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trn_gini      trn_mae      trn_rmse  test_gini      test_mae     test_rmse\n",
       "0   0.29784  9674.240242  22346.456421   0.284799  11245.016619  22120.953015"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ScoresFinal = pd.DataFrame(list(zip(trn_gini_l, trn_mae_l, trn_rmse_l, test_gini_l, test_mae_l, test_rmse_l )), \n",
    "               columns =['trn_gini','trn_mae','trn_rmse','test_gini','test_mae','test_rmse'])\n",
    "ScoresFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------\n",
    "training_dataset.to_csv('%sproperty_wcs_training_for_normal.csv'%DataDir,header=True,index=False)\n",
    "testing_dataset.to_csv('%sproperty_wcf_testing.csv'%DataDir,header=True,index=False)\n",
    "prediction_dataset.to_csv('%sproperty_water_claims_non_cat_fs.csv'%DataDir,header=True,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
