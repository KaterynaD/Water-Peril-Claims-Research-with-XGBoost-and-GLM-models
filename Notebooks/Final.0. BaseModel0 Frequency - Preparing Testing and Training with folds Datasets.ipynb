{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = '/home/kate/Research/Property/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(data_folder+'property_water_claims_non_cat_fs_v5.csv', error_bad_lines=False, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureset  = [\n",
    "'roofcd',\n",
    "'roofcd_encd',\n",
    "'sqft',\n",
    "'log_sqft',\n",
    "'usagetype',    \n",
    "'usagetype_encd',\n",
    "'yearbuilt',\n",
    "'log_yearbuilt',\n",
    "'water_risk_3_blk',\n",
    "'log_water_risk_3_blk', \n",
    "'landlordind',\n",
    "'multipolicyind'   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_column= 'hasclaim' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold =5 \n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_column= 'hasclaim' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataset  for classification excluding 2019 and 2020\n",
      "Training Size Original = 1925116\n",
      "Training Size of unique values = 250685\n",
      "Creating folds\n",
      " fold: 1  of  5 : \n",
      " fold: 2  of  5 : \n",
      " fold: 3  of  5 : \n",
      " fold: 4  of  5 : \n",
      " fold: 5  of  5 : \n",
      "Saving training dataset for classification\n"
     ]
    }
   ],
   "source": [
    "print('Creating training dataset  for classification excluding 2019 and 2020')\n",
    "training_dataset=dataset[(dataset.cal_year != 2019) & (dataset.cal_year != 2020) ][featureset + [target_column]]\n",
    "print('Training Size Original = %s'%len(training_dataset))\n",
    "training_dataset = training_dataset.drop_duplicates(featureset + [target_column])\n",
    "print('Training Size of unique values = %s'%len(training_dataset))\n",
    "print('Creating folds')\n",
    "for i, (train_index, test_index) in enumerate(skf.split(training_dataset[featureset], training_dataset[target_column])):\n",
    "    print(' fold: {}  of  {} : '.format(i+1, kfold))\n",
    "    training_dataset['fold_%s'%i]=0\n",
    "    training_dataset.iloc[train_index,training_dataset.columns.get_loc('fold_%s'%i)]=1\n",
    "print('Saving training dataset for classification')\n",
    "training_dataset.to_csv('%sproperty_wcf_class_training_basemodel0.csv'%(data_folder),header=True,index=False)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
