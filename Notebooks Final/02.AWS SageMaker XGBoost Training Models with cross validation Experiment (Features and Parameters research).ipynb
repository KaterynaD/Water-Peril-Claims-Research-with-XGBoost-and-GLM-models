{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS SageMaker XGBoost Classification Training Models with cross validation Experiment (Features and Parameters research)\n",
    "\n",
    "Purpose: Based on the configured list of features and/or parameters train several models to compare results. Each model is a set of cross validation folds.\n",
    "\n",
    "The idea is to do a **deep**  model comparison with the same method (XGBoost Classification), target variable and dataset but different sets of features and/or parameters. \n",
    "\n",
    "The models can be trained in parallel and even with a large dataste, the result is available relatively soon comparing to sequntial run on a local server.\n",
    "\n",
    "The output is not just a model and score (ROC-AUC) but also feature importance, test dataset evaluation score and training/validation errors to analyze overfitting.\n",
    "\n",
    "OpenSource XGBoost is used in the script but it can be easily replaced with SageMaker built-in XGBoost (except returning feature importance, test dataset evaluatin scores and training/validation errors to analyze overfitting). \n",
    "\n",
    "The advantage of using this notebook over the next one (03.AWS... native XGBoost CV) is for more parallelism. Each fold is trained in parallel. It maybe be better for larger datasets but  on the other hand, will require more simultaneously running training jobs and there is a limit in AWS for large instances running in parallel.\n",
    "\n",
    "The notebook uses the same approach and scripts for models training as 01.AWS... The only difference is experiment results post processing.\n",
    "\n",
    "\n",
    "#### Custom evaluation metrics\n",
    "\n",
    "Only in OpenSource XGBoost custom evaluation metrics can be defined and used for model training directly in the script used for training. However, AWS Sagemaker monitoring system, charts and experiments do not see them. Custom evaluation metrics should be configured in metric_defintions.\n",
    "\n",
    "OpenSource SageMaker XGBoost (as in March 2021 version 1.2-1) is incorrectly recognizing XGBoost as a built-in algorithm and using metric definition raise the error:\n",
    "An error occurred (ValidationException) when calling the CreateTrainingJob operation: You can't override the metric definitions for Amazon SageMaker algorithms. Please retry the request without specifying metric definitions.\n",
    "\n",
    "There are 2 approached to make AWS SageMaker fully functional.\n",
    "\n",
    "**The first one is just to name the custom function as a standard one.**\n",
    "\n",
    "The trick is:\n",
    "1. Create a function to calculate custom metric (gini). If it's named gini it will be used in training but NOT visible for experiments or hyperparameters tuning.\n",
    "2. Name it as a standard score (auc_xgb instead of gini_xgb) \n",
    "3. Disable using a standard score in the parameters: 'disable_default_eval_metric': '1', and do not add eval_metric at all.\n",
    "\n",
    "That's easily can be accomplished just in the script used for training.\n",
    "\n",
    "**The second approach is more complex and require more efforts**\n",
    "\n",
    "The workaround is to create your own container from the official AWS Sagemaker Open Source XGBoost GitHub repository, host it in your own ECR repository, and use this image from Python SDK. \n",
    "\n",
    "Steps to create your own ECR repository:\n",
    "\n",
    "1. Install and configure aws-cli (https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html and https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html)\n",
    "\n",
    "2. Install docker (https://docs.docker.com/engine/install/ubuntu/) or just add your user to the docker group (Some steps below do not work when docker used via sudo)\n",
    "- sudo usermod -aG docker kate\n",
    "Activate the changes to groups\n",
    "- newgrp docker\n",
    "Verify that you can run docker commands without sudo\n",
    "- docker run hello-world\n",
    "3. Build container\n",
    "- git clone https://github.com/aws/sagemaker-xgboost-container\n",
    "- docker build -t xgboost-container-base:1.2-1-cpu-py3 -f docker/1.0-1/base/Dockerfile.cpu .\n",
    "- python setup.py bdist_wheel --universal\n",
    "- docker build -t preprod-xgboost-container:1.2-1-cpu-py3 -f docker/1.2-1/final/Dockerfile.cpu .\n",
    "4. Create ECR repository and push the above image.\n",
    "- eval $(aws ecr get-login --region  us-west-2 --no-include-email | sed 's|https://||')\n",
    "- aws ecr create-repository --repository-name sagemaker-xgboost --region us-west-2\n",
    "- docker tag preprod-xgboost-container:1.2-1-cpu-py3 XYZ.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:1.2-1-cpu-py3\n",
    "- docker push XYZ.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:1.2-1-cpu-py3\n",
    "5. Use image_uri=XYZ.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:1.2-1-cpu-py3 in XGBoost()\n",
    "\n",
    "#### Notebook Main steps:\n",
    "\n",
    "1. Experiment configuration. Instead of hardcoding datafile name, target variable, featuresets and parameters sets directly in the code I use an Excel file. Each tab with a predefined name contains featuresets for each model or parameter sets, etc. At the end, the code records the results back into the same excel file. Excel is used as an UI to easily configure experiment. \n",
    "\n",
    "AWS SageMaker Experiment is used also but I did not find it's very useful to track the featuresets and process and visaulaize the results (available in SageMaker notebook).  I need to average data before comparing and take into account sem.\n",
    "\n",
    "2. Preparing training and validation datasets in configured number of folds (num_folds) - data preprocessing - in S3 in a format suitable for AWS Sagemaker. SKLearnProcessor and a processing job are used to create all datasets for all models in one process but the same can be done directly in the script and only the result can be moved to S3. If the datasets can be re-used from a previous experiment, only S3 location to the files can be configured instead.\n",
    "Usually, testing different featuretests requires creation individual datasets per testing model and different parameters can be tested on the same dataset.\n",
    "\n",
    "\n",
    "3. Training each model is done in parallel. The number of simultaneously running training jobs is contolled by a parameter (MaxNumOfRunningModels).\n",
    "\n",
    "4. Extracting results, visualization, performing t-test and saving to an experiment log file. This is done for averaged results from all folds per model. \n",
    "\n",
    "\n",
    "#### Known issues:\n",
    "1. Warnings after upgrading SageMaker to version 2:\n",
    "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
    "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
    "Looks like warnings from XGBoost open-source estimator. No clear information about the parameters\n",
    "2. All models artifacts are saved into output_path provided as a parameter to the estimator (expected only model.tar.gz) except source/sourcedir.tar.gz which is saved into toot of a bucket from output_path. Previously everything except model.tar.gz was saved into default bucket\n",
    "3. As on Mar/2021 open source, script mode, AWS SageMaker XGBoost is still recognized like a standard, built-in algorithm and prevent us using custom metric definitions.\n",
    "See https://github.com/aws/sagemaker-xgboost-container/issues/121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder='/home/kate/Research/Property/Notebooks/Experiments/tmp/'\n",
    "#Experiment_name must NOT contain underscore (_)\n",
    "Experiment_name='FeatureSet'\n",
    "#Experiments log file\n",
    "Experiments_file='/home/kate/Research/Property/Notebooks/Experiments/Logs/Set1-Classification.xlsx'\n",
    "#AllExperiments_tab is a table with a list of all experiments included in the log\n",
    "#Mandatory columns: Experiment (Experiment_name), Dataset(data file name), Target(target column name from Dataset)\n",
    "#The rest of the columns are not use in the code below. I usually add in a free form: objective,status,result,notebook name used to conduct the experiment\n",
    "AllExperiments_tab='Experiments'\n",
    "#Experiment configuration:\n",
    "#1.Experiment_Features_tab: differenet datasets to try\n",
    "#each line in the tab contains a model name and set of features to built a dataset for SageMaker\n",
    "#a feature can be an exact column name from the Dataset column in AllExperiments_tab or a calculation based on exact column names and eval pandas function\n",
    "#if the experiment objective is to try different parameters sets, all models (if more then 1) can have the same feature sets.\n",
    "Experiment_Features_tab='%s Features'%Experiment_name\n",
    "#2. Alternatively a set of data files with preprocessed data in S3 can be provided in a form:\n",
    "#Model,Training_data,Validation_data[, Testing_data, Testing_labels]\n",
    "Experiment_InputData_tab='%s InputData'%Experiment_name\n",
    "#3. Experiment_Params_tab: each line in the tab contains a model name and set of XGBoost parametersto apply to a model\n",
    "#the set of models should be consistent in Experiment_Features_tab and Experiment_Params_tab\n",
    "#parameters can be the same for all models or specific in each model\n",
    "Experiment_Params_tab='%s Params'%Experiment_name\n",
    "\n",
    "#Trial names in AWS Sage Maker experiment\n",
    "Trial_name_preprocessing='%s-PreparingTrainValidData'%Experiment_name\n",
    "Trial_name_training='%s-TrainingModels'%Experiment_name\n",
    "\n",
    "#everything stored in\n",
    "bucket='kdproperty'\n",
    "\n",
    "path_to_data='Data'\n",
    "path_to_training_data='Data/Experiments/%s/training'%Experiment_name\n",
    "path_to_validation_data='Data/Experiments/%s/validation'%Experiment_name\n",
    "path_to_testing_data='Data/Experiments/%s/testing'%Experiment_name\n",
    "path_to_testing_labels='Data/Experiments/%s/labels'%Experiment_name\n",
    "path_to_configuration='Config'\n",
    "path_to_models='Models/Experiments/%s'%Experiment_name\n",
    "\n",
    "#preprocessing parameters\n",
    "split_year='2019'\n",
    "\n",
    "#number of folds for CV\n",
    "num_folds='10'\n",
    "\n",
    "#entry_point defines a script to be run for model training\n",
    "#the scripts have different ouput and metric defnitions should be adjusted accordingly\n",
    "entry_point='ModelTraining_Gini_EvalMetric.py' #'ModelTraining_Gini_named_AUC_EvalMetric.py' #'ModelTraining_Gini_EvalMetric.py' #'ModelTraining.py' uses a standard XGBoost metric (auc), no need for custom image_uri in XGBoost and metric definitions. \n",
    "# ModelTraining_Gini_named_AUC_EvalMetric.py uses XGBoost training with custom evaluation metric - gini, but the name of teh custom function inside the script is auc, \n",
    "# no need for custom image_uri in XGBoost and metric definitions.\n",
    "# ModelTraining_Gini_EvalMetric.py uses XGBoost training with custom evaluation metric - gini. Use custom image_uri and metric defnitions.\n",
    "\n",
    "\n",
    "#just a placeholder. the parameter can be commented in XGBoostbor just leave it as empty string. It's used when standard metrics are used.\n",
    "stnadard_image_uri=''\n",
    "#it's needed as a workaround to be able to work with custom metrics and scripts output in AWS Sagemaker montitor systems, charts and experiment\n",
    "custom_image_uri='757107622481.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:1.2-1-cpu-py3'\n",
    "\n",
    "#level of details returning from CV\n",
    "#any Y return models from a best iteration\n",
    "#FeatureImportance Y/N\n",
    "GetFIFlg='Y'\n",
    "#Scores for Test data (should be provided in fit \"test\" input) Y/N\n",
    "GetTestScoreFlg='Y'\n",
    "#Prediction of Test data (should be provided in fit \"test\" input) Y/N\n",
    "GetTestPredFlg='Y'  \n",
    "\n",
    "\n",
    "#Significance level for t-test\n",
    "alpha=0.05\n",
    "\n",
    "#n2/n1 (validation/training) ratio for corrected t-test if n2=n1 or n2/n1 = 1 then it's just usual Student t-test withoot correction\n",
    "#10 folds means 1/9 validation/training ratio \n",
    "n2=1\n",
    "n1=9\n",
    "\n",
    "preprocessing_instance_type='ml.t3.large'\n",
    "preprocessing_instance_count=1\n",
    "\n",
    "#Training parameters\n",
    "training_instance_type='ml.c5.xlarge'\n",
    "training_instance_count=1\n",
    "\n",
    "#How many simultaneously running training jobs we want to see in the system\n",
    "MaxNumOfRunningModels = 30\n",
    "#when a job is completes/failed or stopped a new one can be added Jobs status is checked periodically\n",
    "check_training_job_every_sec=10\n",
    "\n",
    "#What to do with th2 experiment (rest of running jobs) if a training job failed or stopped\n",
    "StopOnFailedModel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import boto3\n",
    "\n",
    "import s3fs\n",
    "import tarfile\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.session import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be run as a first step\n",
    "#role arn is used when run from a local machine\n",
    "sagemaker_execution_role = 'arn:aws:iam::757107622481:role/service-role/AmazonSageMaker-ExecutionRole-20200819T131882'\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "s3 = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "Experiment is configured in an experiment log file (Excel file, in my case,  in different tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reading an experiment configuration (Experiment_name) from an experiment log file (Experiments_file). Target and Dataset columns in AllExperiments_tab contain data file name used and target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=AllExperiments_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target of models in FeatureSet experiment is hasclaim\n",
      "Datafile used in FeatureSet experiment is property_water_claims_non_cat_fs_v5.csv\n"
     ]
    }
   ],
   "source": [
    "target=experiments[experiments['Experiment']==Experiment_name]['Target'].values[0]\n",
    "print('Target of models in %s experiment is %s'%(Experiment_name,target))\n",
    "data_file=experiments[experiments['Experiment']==Experiment_name]['Dataset'].values[0]\n",
    "print('Datafile used in %s experiment is %s'%(Experiment_name,data_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Models based on individual datasets to be created, trained and compared in the experiment (Experiment_Features_tab) is a table with first column Model name (should be unique) and next columns [1:51] features to train the model. Feature is the exact column name from the dataset or a calculation based on exact column names and eval pandas function\n",
    "\n",
    "This configuration will be used to preprocess data and also need to be moved to S3 in csv format for easy reading in a preprocessing script if we use AWS SKLearnProcessor/job/instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoPlumbLeak</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nocovalimit</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nopool</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoWaterRisk</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nolandlord</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoPipeFroze</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Norplcostdwel</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nousagetype</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model1</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Model2</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model3</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model                  F1               F2    F3  \\\n",
       "0       BaseModel  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "1     NoPlumbLeak  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "2     Nocovalimit  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "3          Nopool  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "4     NoWaterRisk  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "5      Nolandlord  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "6     NoPipeFroze  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "7   Norplcostdwel  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "8     Nousagetype  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "9          Model1  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "10         Model2  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "11         Model3  cal_year-yearbuilt  cova_deductible  sqft   \n",
       "\n",
       "                              F4                F5  \\\n",
       "0   customer_cnt_active_policies    usagetype_encd   \n",
       "1   customer_cnt_active_policies    usagetype_encd   \n",
       "2   customer_cnt_active_policies    usagetype_encd   \n",
       "3   customer_cnt_active_policies    usagetype_encd   \n",
       "4   customer_cnt_active_policies    usagetype_encd   \n",
       "5   customer_cnt_active_policies    usagetype_encd   \n",
       "6   customer_cnt_active_policies    usagetype_encd   \n",
       "7   customer_cnt_active_policies    usagetype_encd   \n",
       "8   customer_cnt_active_policies               NaN   \n",
       "9   customer_cnt_active_policies    usagetype_encd   \n",
       "10                   landlordind    usagetype_encd   \n",
       "11                usagetype_encd  water_risk_3_blk   \n",
       "\n",
       "                            F6                F7           F8  \\\n",
       "0   replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "1   replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "2   replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "3   replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "4   replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "5   replacementcostdwellingind  pipe_froze_3_blk          NaN   \n",
       "6   replacementcostdwellingind               NaN          NaN   \n",
       "7                          NaN               NaN          NaN   \n",
       "8                          NaN               NaN          NaN   \n",
       "9             water_risk_3_blk               NaN          NaN   \n",
       "10            water_risk_3_blk               NaN          NaN   \n",
       "11                         NaN               NaN          NaN   \n",
       "\n",
       "                  F9      F10         F11               F12  \n",
       "0   water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "1   water_risk_3_blk  poolind  cova_limit               NaN  \n",
       "2   water_risk_3_blk  poolind         NaN               NaN  \n",
       "3   water_risk_3_blk      NaN         NaN               NaN  \n",
       "4                NaN      NaN         NaN               NaN  \n",
       "5                NaN      NaN         NaN               NaN  \n",
       "6                NaN      NaN         NaN               NaN  \n",
       "7                NaN      NaN         NaN               NaN  \n",
       "8                NaN      NaN         NaN               NaN  \n",
       "9                NaN      NaN         NaN               NaN  \n",
       "10               NaN      NaN         NaN               NaN  \n",
       "11               NaN      NaN         NaN               NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_features = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_Features_tab)\n",
    "model_features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we may need to get mapping between f0 - fN features in the dataset and feature importance output based on Modelname\n",
    "def GetMap(model):\n",
    "    feature_map={}\n",
    "    df=model_features[model_features['Model']==model].loc[:, model_features.columns != 'Model']\n",
    "    for i,c in enumerate(df.columns):\n",
    "        feature_map['f%s'%i]=df[c].values[0]\n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2a.Preprocessed data may already exists in an S3. Experiment configuration can provide the list of files per model. In this case (len(preprocessed_data)==0) the code skips all steps to preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    preprocessed_data = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_InputData_tab)\n",
    "except:\n",
    "    preprocessed_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>fold</th>\n",
       "      <th>Training_data</th>\n",
       "      <th>Validation_data</th>\n",
       "      <th>Testing_data</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>2</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>3</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>4</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Model3</td>\n",
       "      <td>5</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Model3</td>\n",
       "      <td>6</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Model3</td>\n",
       "      <td>7</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Model3</td>\n",
       "      <td>8</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Model3</td>\n",
       "      <td>9</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  fold                                      Training_data  \\\n",
       "0    BaseModel     0  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "1    BaseModel     1  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "2    BaseModel     2  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "3    BaseModel     3  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "4    BaseModel     4  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "..         ...   ...                                                ...   \n",
       "115     Model3     5  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "116     Model3     6  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "117     Model3     7  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "118     Model3     8  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "119     Model3     9  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "\n",
       "                                       Validation_data  \\\n",
       "0    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "1    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "2    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "3    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "4    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "..                                                 ...   \n",
       "115  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "116  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "117  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "118  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "119  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "\n",
       "                                          Testing_data                  F1  \\\n",
       "0    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "1    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "2    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "3    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "4    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "..                                                 ...                 ...   \n",
       "115  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "116  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "117  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "118  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "119  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "\n",
       "                  F2    F3                            F4                F5  \\\n",
       "0    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "1    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "2    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "3    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "4    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "..               ...   ...                           ...               ...   \n",
       "115  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "116  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "117  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "118  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "119  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "\n",
       "                             F6                F7           F8  \\\n",
       "0    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "1    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "2    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "3    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "4    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "..                          ...               ...          ...   \n",
       "115                         NaN               NaN          NaN   \n",
       "116                         NaN               NaN          NaN   \n",
       "117                         NaN               NaN          NaN   \n",
       "118                         NaN               NaN          NaN   \n",
       "119                         NaN               NaN          NaN   \n",
       "\n",
       "                   F9      F10         F11               F12  \n",
       "0    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "1    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "2    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "3    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "4    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "..                ...      ...         ...               ...  \n",
       "115               NaN      NaN         NaN               NaN  \n",
       "116               NaN      NaN         NaN               NaN  \n",
       "117               NaN      NaN         NaN               NaN  \n",
       "118               NaN      NaN         NaN               NaN  \n",
       "119               NaN      NaN         NaN               NaN  \n",
       "\n",
       "[120 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b.Saving into S3 models configurations (sets of features) to be used in data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(preprocessed_data)==0:\n",
    "    Model_Config_file='%s.csv'%Experiment_name\n",
    "    Models_Config_path = os.path.join(temp_folder, Model_Config_file) \n",
    "\n",
    "    model_features.to_csv(Models_Config_path, header=True, index=False)\n",
    "\n",
    "\n",
    "    input_code = sagemaker_session.upload_data(\n",
    "        Models_Config_path,\n",
    "        bucket=bucket,\n",
    "        key_prefix=path_to_configuration\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model params to be used in training is a table with first column Model name (should be unique and corresponds to models in Experiment_Features_tab) and next columns are XGBoost parameters\n",
    "In a general case, all models can have the same parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>objective</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>booster</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>eta</th>\n",
       "      <th>subsample</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>num_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoPlumbLeak</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nocovalimit</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nopool</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoWaterRisk</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nolandlord</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoPipeFroze</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Norplcostdwel</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nousagetype</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model1</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Model2</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model3</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model        objective eval_metric booster  scale_pos_weight  \\\n",
       "0       BaseModel  binary:logistic         auc  gbtree               0.3   \n",
       "1     NoPlumbLeak  binary:logistic         auc  gbtree               0.3   \n",
       "2     Nocovalimit  binary:logistic         auc  gbtree               0.3   \n",
       "3          Nopool  binary:logistic         auc  gbtree               0.3   \n",
       "4     NoWaterRisk  binary:logistic         auc  gbtree               0.3   \n",
       "5      Nolandlord  binary:logistic         auc  gbtree               0.3   \n",
       "6     NoPipeFroze  binary:logistic         auc  gbtree               0.3   \n",
       "7   Norplcostdwel  binary:logistic         auc  gbtree               0.3   \n",
       "8     Nousagetype  binary:logistic         auc  gbtree               0.3   \n",
       "9          Model1  binary:logistic         auc  gbtree               0.3   \n",
       "10         Model2  binary:logistic         auc  gbtree               0.3   \n",
       "11         Model3  binary:logistic         auc  gbtree               0.3   \n",
       "\n",
       "    colsample_bylevel  colsample_bytree   eta  subsample  max_depth  num_round  \n",
       "0                 0.8               0.8  0.04        0.6          6       5000  \n",
       "1                 0.8               0.8  0.04        0.6          6       5000  \n",
       "2                 0.8               0.8  0.04        0.6          6       5000  \n",
       "3                 0.8               0.8  0.04        0.6          6       5000  \n",
       "4                 0.8               0.8  0.04        0.6          6       5000  \n",
       "5                 0.8               0.8  0.04        0.6          6       5000  \n",
       "6                 0.8               0.8  0.04        0.6          6       5000  \n",
       "7                 0.8               0.8  0.04        0.6          6       5000  \n",
       "8                 0.8               0.8  0.04        0.6          6       5000  \n",
       "9                 0.8               0.8  0.04        0.6          6       5000  \n",
       "10                0.8               0.8  0.04        0.6          6       5000  \n",
       "11                0.8               0.8  0.04        0.6          6       5000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_Params_tab)\n",
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Verification if we have the same set of models in both configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_from_model_features=model_features['Model'].tolist()\n",
    "models_from_model_params=model_params['Model'].tolist()\n",
    "if len([x for x in models_from_model_features if x not in models_from_model_params])!=0:\n",
    "    raise Exception('Different set of models in featuresets and parametersets!')\n",
    "if len(preprocessed_data)>0:\n",
    "    models_from_preprocessed_data=preprocessed_data['Model'].tolist()\n",
    "    if len([x for x in models_from_preprocessed_data if x not in models_from_model_params])!=0:\n",
    "        raise Exception('Different set of models in input data and parametersets!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Creating experiments and trials in SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append('/home/kate/Research/YearBuilt/Notebooks/Experiments')\n",
    "import ExperimentsUtils as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "eu.cleanup_experiment(Experiment_name)\n",
    "eu.create_experiment(Experiment_name)\n",
    "eu.create_trial(Experiment_name,Trial_name_preprocessing)\n",
    "eu.create_trial(Experiment_name,Trial_name_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We may not need an AWS SKLearnProcessor/job/instances for relatively small and medium datasets (unless our data are already in S3 and it takes time and money to download)\n",
    "What's important is to save the prepared datasets in a predefined S3 location to be used in training.\n",
    "In a case of really huge datasets and instensive, time consuming preprocessing, a separate SKLearnProcessor/job for each model can be created with more then 1 powerful instance.\n",
    "\n",
    "Preprocessing script below reads the data from the input dataset, model configurations (desired featuresets), seprate 2020 (split_year) as a test dataset (not used in the experiment, because the data may be not complete developed in the year) and split the rest of the data to training and validation folds. \n",
    "\n",
    "Training and validation datasets are saved in AWS SageMaker form (first column is a target, no header) in csv format. The location and filenames are based on model names: folder name is a model name and file names also contain a model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessingStratifiedKFold_for_all_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessingStratifiedKFold_for_all_models.py\n",
    "\n",
    "#Training and Validation dataset for SageMaker are the same structure: no headers, the first column is a target and the rest are features\n",
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_file', type=str)\n",
    "    parser.add_argument('--split_year', type=int)   \n",
    "    parser.add_argument('--num_folds', type=int)      \n",
    "    parser.add_argument('--target', type=str)      \n",
    "    parser.add_argument('--config_file', type=str)     \n",
    "    args, _ = parser.parse_known_args()    \n",
    "    print('Received arguments {}'.format(args))\n",
    "    \n",
    "    target_column=args.target\n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', args.data_file)\n",
    "    config_data_path = os.path.join('/opt/ml/processing/config', args.config_file)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    print('Reading input data from {}'.format(input_data_path))\n",
    "    dataset = pd.read_csv(input_data_path, error_bad_lines=False, index_col=False)\n",
    "    dataset_test=dataset[(dataset.cal_year == args.split_year)]\n",
    "    dataset=dataset[(dataset.cal_year < args.split_year)]    \n",
    "    \n",
    "\n",
    "    print('Reading config data from {}'.format(config_data_path))\n",
    "    models = pd.read_csv(config_data_path, error_bad_lines=False, index_col=False) \n",
    "    \n",
    "           \n",
    "    #StratifiedKFold\n",
    "    kfold =args.num_folds \n",
    "    skf = StratifiedKFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    \n",
    "    #iterating thru config file with models and featureset\n",
    "    for index, row in models.iterrows():\n",
    "        model=row['Model']\n",
    "        print (index, ': Creating datasets for model %s'%model)\n",
    "        featureset=row[1:51].tolist()\n",
    "        featureset=[x for x in featureset if str(x) != 'nan']\n",
    "        print(','.join(featureset))\n",
    "        \n",
    "        #creating dataset for a model according to configured dataset\n",
    "        X = pd.DataFrame()\n",
    "        X_test = pd.DataFrame()  \n",
    "        for f in featureset:\n",
    "            X[f]=dataset.eval(f)\n",
    "            X_test[f]=dataset_test.eval(f)             \n",
    "        y=dataset.eval(target_column)    \n",
    "        y_test=dataset_test.eval(target_column) \n",
    "\n",
    "        #Testing data starts from y_test because they are read in XGBoost processing script to DMatrix amd first column is separated anyway\n",
    "        #Without the column the script can not predict\n",
    "        print('Testing data...')\n",
    "        test_data_output_path = '/opt/ml/processing/output/testing_data/%s/'%model              \n",
    "        if not os.path.exists(test_data_output_path):\n",
    "            os.makedirs(test_data_output_path)       \n",
    "        test_data_output_path = os.path.join(test_data_output_path,  'testing_%s.csv'%(model))  \n",
    "        test_dataset=pd.DataFrame({target_column:y_test}).join(X_test)\n",
    "        test_dataset.to_csv(test_data_output_path, header=False, index=False)\n",
    "        \n",
    "        #The rest of the data will be used in cv-fold as a whole and seprated to training/validation insode cv        \n",
    "        for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            print(' fold: {}  of  {} : '.format(i+1, kfold))\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[test_index] \n",
    "\n",
    "            train_data_output_path = '/opt/ml/processing/output/training_data/%s/'%model              \n",
    "            if not os.path.exists(train_data_output_path):\n",
    "                os.makedirs(train_data_output_path)\n",
    "            train_data_output_path_fold = os.path.join(train_data_output_path,  'fold_%s_training_%s.csv'%(model,i))\n",
    "            \n",
    "            validation_data_output_path = '/opt/ml/processing/output/validation_data/%s/'%model  \n",
    "            if not os.path.exists(validation_data_output_path):\n",
    "                os.makedirs(validation_data_output_path)            \n",
    "            validation_data_output_path_fold = os.path.join(validation_data_output_path, 'fold_%s_validation_%s.csv'%(model,i))       \n",
    "        \n",
    "            training_dataset=pd.DataFrame({target_column:y_train}).join(X_train)\n",
    "            training_dataset.to_csv(train_data_output_path_fold, header=False, index=False)\n",
    "                                                   \n",
    "            validation_dataset=pd.DataFrame({target_column:y_valid}).join(X_valid)   \n",
    "            validation_dataset.to_csv(validation_data_output_path_fold, header=False, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already preprocessed in S3\n"
     ]
    }
   ],
   "source": [
    "if len(preprocessed_data)==0:\n",
    "    data_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=sagemaker_execution_role,\n",
    "                                     instance_type=preprocessing_instance_type,\n",
    "                                     instance_count=preprocessing_instance_count)    \n",
    "    data_processor.run(code='preprocessingStratifiedKFold_for_all_models.py',\n",
    "                            inputs=[ProcessingInput(input_name='data',source='s3://%s/%s/%s'%(bucket,path_to_data,data_file),destination='/opt/ml/processing/input'),\n",
    "            ProcessingInput(input_name='config',source='s3://%s/%s/%s'%(bucket,path_to_configuration,Model_Config_file),destination='/opt/ml/processing/config'),\n",
    "                                   ],\n",
    "                        outputs=[ProcessingOutput(output_name='training_data', source='/opt/ml/processing/output/training_data',destination='s3://%s/%s/'%(bucket,path_to_training_data)),                                 \n",
    "                                 ProcessingOutput(output_name='validation_data', source='/opt/ml/processing/output/validation_data',destination='s3://%s/%s/'%(bucket,path_to_validation_data)),                                      \n",
    "                                 ProcessingOutput(output_name='testing_data', source='/opt/ml/processing/output/testing_data',destination='s3://%s/%s/'%(bucket,path_to_testing_data))\n",
    "                                ],\n",
    "                        arguments=['--data_file',data_file,\n",
    "                                 '--split_year',split_year,\n",
    "                                 '--num_folds',num_folds,  \n",
    "                                 '--target',target,                                    \n",
    "                                 '--config_file',Model_Config_file],\n",
    "                        experiment_config = {\n",
    "        'ExperimentName': Experiment_name ,\n",
    "        'TrialName' : Trial_name_preprocessing,\n",
    "        'TrialComponentDisplayName' : '%s-%s'%(Trial_name_preprocessing,'-'+time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())),},\n",
    "                    wait=True\n",
    "                     )\n",
    "else:\n",
    "    print('Data already preprocessed in S3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in a case a previous step started preproceesin (nothing provided in InputData) Stop the execution if there is an issue with creating input data for the models\n",
    "if len(preprocessed_data)==0:\n",
    "    job_name=data_processor.jobs[-1].describe()['ProcessingJobName']\n",
    "    if not(sagemaker_session.was_processing_job_successful(job_name)):\n",
    "        raise Exception('Preprocessing job Failed!')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preprocessing output (training and validation datasets) is saved separately for each model and fold in a folder with the same name as a models name configured in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>fold</th>\n",
       "      <th>Training_data</th>\n",
       "      <th>Validation_data</th>\n",
       "      <th>Testing_data</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>2</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>3</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>4</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Model3</td>\n",
       "      <td>5</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Model3</td>\n",
       "      <td>6</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Model3</td>\n",
       "      <td>7</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Model3</td>\n",
       "      <td>8</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Model3</td>\n",
       "      <td>9</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/tr...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/te...</td>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  fold                                      Training_data  \\\n",
       "0    BaseModel     0  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "1    BaseModel     1  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "2    BaseModel     2  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "3    BaseModel     3  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "4    BaseModel     4  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "..         ...   ...                                                ...   \n",
       "115     Model3     5  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "116     Model3     6  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "117     Model3     7  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "118     Model3     8  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "119     Model3     9  s3://kdproperty/Data/Experiments/FeatureSet/tr...   \n",
       "\n",
       "                                       Validation_data  \\\n",
       "0    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "1    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "2    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "3    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "4    s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "..                                                 ...   \n",
       "115  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "116  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "117  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "118  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "119  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "\n",
       "                                          Testing_data                  F1  \\\n",
       "0    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "1    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "2    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "3    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "4    s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "..                                                 ...                 ...   \n",
       "115  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "116  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "117  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "118  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "119  s3://kdproperty/Data/Experiments/FeatureSet/te...  cal_year-yearbuilt   \n",
       "\n",
       "                  F2    F3                            F4                F5  \\\n",
       "0    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "1    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "2    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "3    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "4    cova_deductible  sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "..               ...   ...                           ...               ...   \n",
       "115  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "116  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "117  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "118  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "119  cova_deductible  sqft                usagetype_encd  water_risk_3_blk   \n",
       "\n",
       "                             F6                F7           F8  \\\n",
       "0    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "1    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "2    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "3    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "4    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "..                          ...               ...          ...   \n",
       "115                         NaN               NaN          NaN   \n",
       "116                         NaN               NaN          NaN   \n",
       "117                         NaN               NaN          NaN   \n",
       "118                         NaN               NaN          NaN   \n",
       "119                         NaN               NaN          NaN   \n",
       "\n",
       "                   F9      F10         F11               F12  \n",
       "0    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "1    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "2    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "3    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "4    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "..                ...      ...         ...               ...  \n",
       "115               NaN      NaN         NaN               NaN  \n",
       "116               NaN      NaN         NaN               NaN  \n",
       "117               NaN      NaN         NaN               NaN  \n",
       "118               NaN      NaN         NaN               NaN  \n",
       "119               NaN      NaN         NaN               NaN  \n",
       "\n",
       "[120 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#was not tested with different feature sets (more then 1 row in model_feature)\n",
    "#preprocessed_data=preprocessed_data[0:0]\n",
    "if len(preprocessed_data)==0:\n",
    "    j=0\n",
    "    for index, row in model_features.iterrows():\n",
    "        model=row['Model']\n",
    "        folds_preprocessed_data = pd.DataFrame(columns=['Model','fold', 'Training_data', 'Validation_data', 'Testing_data'])\n",
    "        for i in range(0,int(num_folds),1):\n",
    "            train_input = 's3://%s/%s/%s/fold_%s_training_%s.csv'%(bucket,path_to_training_data,model,model,i)\n",
    "            validation_input = 's3://%s/%s/%s/fold_%s_validation_%s.csv'%(bucket,path_to_validation_data,model,model,i)\n",
    "            test_data = 's3://%s/%s/%s/testing_%s.csv'%(bucket,path_to_testing_data,model,model) \n",
    "            folds_preprocessed_data.loc[j]=[model, i,  train_input,validation_input,test_data]\n",
    "            j=j+1\n",
    "        folds_preprocessed_data = pd.merge(folds_preprocessed_data,model_features,on='Model', how='inner')\n",
    "        preprocessed_data = pd.concat([preprocessed_data, folds_preprocessed_data], axis=0)\n",
    "    #Saving into the Experiment log file names of created training and validation datasets in S3\n",
    "    eu.SaveToExperimentLog(Experiments_file, '%s InputData'%Experiment_name, preprocessed_data)\n",
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Custom script to train a model. It's requred for open-source SageMaker XGBoost container used further in the notebook. The script returns some additional information (feature importance, test dataset scores and train/validation errors) from training for custom processing. The custom output is saved in output.tar.gz.\n",
    " - ModelTraining.py uses standard evaluation metric (AUC), no need for metric definitions or custom image\n",
    " - ModelTraining_Gini_named_AUC_EvalMetric.py uses XGBoost training with custom evaluation metric - gini, but the name of the custom function inside the script is auc, \n",
    "   no need for custom image_uri in XGBoost and metric definitions.\n",
    " - ModelTraining_Gini_EvalMetric.py uses XGBoost training with custom evaluation metric - gini. Use custom image_uri and metric defnitions.\n",
    "You need just one script, configured in entry_point above, and used in XGBoost below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For each parameter set we create an estimator and train it using training and validation datasets created in previous step and saved in a predefined location \n",
    "based on Model name. \n",
    "\n",
    "The train and valid files locations are saved in preprocessed_data dataframe. They are created for each fold.\n",
    "\n",
    "Since we built our training jobs based on preconfigured parameters and train/valid locations the data in 2 configuration must be consistent (the same model names).\n",
    "\n",
    "Only configured number (MaxNumOfRunningModels) of models is running at the same time. The process starts initial MaxNumOfRunningModels models and waits till \n",
    "one of them Complete, Failed or Stopped (StopOnFailedModel=False only).\n",
    "If a model training job Failed or Stopped and StopOnFailedModel is True, the whole process is broken.\n",
    "Since the training and validation data are created for each fold, the resulting table (data_for_training) will consist data for each configured feature set, parameter set and all folds.\n",
    "The total number of training jobs is number of featuresets * folds * number of parametersets. It can be huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ModelTraining.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ModelTraining.py\n",
    "#ModelTraining.py uses standard XGBoost evaluation metric(AUC), no need for metric definitions or custom image\n",
    "\n",
    "\n",
    "#  Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "#  You may not use this file except in compliance with the License.\n",
    "#  A copy of the License is located at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  or in the \"license\" file accompanying this file. This file is distributed\n",
    "#  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "#  express or implied. See the License for the specific language governing\n",
    "#  permissions and limitations under the License.\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from sagemaker_containers import entry_point\n",
    "from sagemaker_xgboost_container.data_utils import get_dmatrix\n",
    "from sagemaker_xgboost_container import distributed\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def _xgb_train(params, dtrain, evals, num_boost_round, early_stopping_rounds, model_dir, output_data_dir, GetFIFlg,GetTestScoreFlg,GetTestPredFlg, is_master):\n",
    "    \"\"\"Run xgb train on arguments given with rabit initialized.\n",
    "\n",
    "    This is our rabit execution function.\n",
    "\n",
    "    :param args_dict: Argument dictionary used to run xgb.train().\n",
    "    :param is_master: True if current node is master host in distributed training,\n",
    "                        or is running single node training job.\n",
    "                        Note that rabit_run will include this argument.\n",
    "    \"\"\"\n",
    "    progress = dict()\n",
    "    booster = xgb.train(params=params,\n",
    "                        dtrain=dtrain,\n",
    "                        evals=evals,\n",
    "                        maximize=True,\n",
    "                        num_boost_round=num_boost_round,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        evals_result=progress,\n",
    "                        verbose_eval=100)\n",
    "    \n",
    "    print('Eval results')    \n",
    "    train_error=progress['train']['auc']\n",
    "    eval_error=progress['validation']['auc']\n",
    "    results_pd=pd.DataFrame({'train':train_error,'valid':eval_error},columns=['train','valid'])\n",
    "    \n",
    "    \n",
    "    #feature importance\n",
    "    if GetFIFlg=='Y':\n",
    "        fi_weight =booster.get_score(importance_type='weight')\n",
    "        fi_gain = booster.get_score(importance_type='gain')\n",
    "        fi_cover= booster.get_score(importance_type='cover')\n",
    "        fi_weight_pd = pd.DataFrame(fi_weight.items(),columns=['feature','weight'])\n",
    "        fi_gain_pd = pd.DataFrame(fi_gain.items(),columns=['feature','gain'])\n",
    "        fi_cover_pd = pd.DataFrame(fi_cover.items(),columns=['feature','cover'])\n",
    "        fi_pd=pd.merge(fi_gain_pd, fi_weight_pd, on='feature', how='inner')\n",
    "        fi_pd=pd.merge(fi_pd, fi_cover_pd, on='feature', how='inner')\n",
    "\n",
    "    #Prediction on test data ...\n",
    "    if 'Y' in (GetTestScoreFlg,GetTestPredFlg):\n",
    "        df_prediction=pd.DataFrame()\n",
    "        df_prediction['actual']=dtest.get_label()\n",
    "        df_prediction['pred']=booster.predict(dtest)\n",
    "   \n",
    "        #Test scores from test prediction   \n",
    "        df_score = pd.DataFrame()\n",
    "        df_score['roc-auc-test']=[roc_auc_score(df_prediction['actual'], df_prediction['pred'])]\n",
    "    \n",
    "    if is_master:\n",
    "        model_location = model_dir + '/xgboost-model'\n",
    "        pkl.dump(booster, open(model_location, 'wb'))\n",
    "        logging.info(\"Stored trained model at {}\".format(model_location))\n",
    "        \n",
    "        if not os.path.exists(output_data_dir):\n",
    "            os.makedirs(output_data_dir)\n",
    "\n",
    "        result_location = os.path.join(output_data_dir, 'eval_results.csv')\n",
    "        print('Saving eval results at {}'.format(result_location))\n",
    "        logging.info('Saving eval results at {}'.format(result_location))\n",
    "        results_pd.to_csv(result_location, header=True, index=False)\n",
    "        \n",
    "        if GetFIFlg=='Y':\n",
    "            fi_location = os.path.join(output_data_dir, 'fi.csv')\n",
    "            print('Saving feature importance at {}'.format(fi_location))\n",
    "            logging.info('Saving feature importance at {}'.format(fi_location))\n",
    "            fi_pd.to_csv(fi_location, header=True, index=False)\n",
    "        \n",
    "        if GetTestPredFlg=='Y':\n",
    "            predictions_location = os.path.join(output_data_dir, 'test_predictions.csv')\n",
    "            print('Saving test predictions at {}'.format(predictions_location))\n",
    "            logging.info('Saving test predictions at {}'.format(predictions_location))\n",
    "            df_prediction.to_csv(predictions_location, header=True, index=False)\n",
    "            \n",
    "        if GetTestScoreFlg=='Y':        \n",
    "            test_score_location = os.path.join(output_data_dir, 'test_score.csv')\n",
    "            print('Saving test score  at {}'.format(test_score_location))\n",
    "            logging.info('Saving test score  at {}'.format(test_score_location))        \n",
    "            df_score.to_csv(test_score_location, header=True, index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters are described here.\n",
    "    parser.add_argument('--max_depth', type=int,)\n",
    "    parser.add_argument('--eta', type=float)\n",
    "    parser.add_argument('--objective', type=str)\n",
    "    parser.add_argument('--num_round', type=int)\n",
    "\n",
    "    parser.add_argument('--early_stopping_rounds', type=int)\n",
    "    parser.add_argument('--booster', type=str)\n",
    "    parser.add_argument('--eval_metric', type=str)\n",
    "    parser.add_argument('--seed', type=int, default=42)\n",
    "    parser.add_argument('--scale_pos_weight', type=float)\n",
    "    parser.add_argument('--colsample_bylevel', type=float)\n",
    "    parser.add_argument('--colsample_bytree', type=float)\n",
    "    parser.add_argument('--subsample', type=float)\n",
    "    parser.add_argument('--max_delta_step', type=int)\n",
    "    \n",
    "    \n",
    "    parser.add_argument('--GetFIFlg', type=str, default='N')\n",
    "    parser.add_argument('--GetTestScoreFlg', type=str, default='N')\n",
    "    parser.add_argument('--GetTestPredFlg', type=str, default='N')            \n",
    "            \n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    \n",
    "    parser.add_argument('--output_data_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    parser.add_argument('--sm_hosts', type=str, default=os.environ.get('SM_HOSTS'))\n",
    "    parser.add_argument('--sm_current_host', type=str, default=os.environ.get('SM_CURRENT_HOST'))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Get SageMaker host information from runtime environment variables\n",
    "    sm_hosts = json.loads(args.sm_hosts)\n",
    "    sm_current_host = args.sm_current_host\n",
    "\n",
    "    dtrain = get_dmatrix(args.train, 'csv')\n",
    "    dval = get_dmatrix(args.validation, 'csv')\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'validation')] if dval is not None else [(dtrain, 'train')]\n",
    "\n",
    "      \n",
    "    dtest = get_dmatrix(args.test, 'csv')\n",
    "    if not(dtest):\n",
    "        if ((args.GetTestScoreFlg=='Y') | (args.GetTestPredFlg=='Y')):\n",
    "            raise Exception('Please provide test data in a test channel for prediction and scores or set GetTestScoreFlg and GetTestPredFlg to N')\n",
    "            \n",
    "    train_hp = {\n",
    "        'max_depth': args.max_depth,\n",
    "        'eta': args.eta,\n",
    "        'objective': args.objective,\n",
    "        'booster': args.booster,\n",
    "        'seed': args.seed,\n",
    "        'eval_metric':args.eval_metric,\n",
    "        'scale_pos_weight':args.scale_pos_weight,\n",
    "        'colsample_bylevel': args.colsample_bylevel,\n",
    "        'colsample_bytree': args.colsample_bytree,\n",
    "        'subsample': args.subsample,\n",
    "        'max_delta_step':args.max_delta_step\n",
    "        }\n",
    "\n",
    "    xgb_train_args = dict(\n",
    "        params=train_hp,\n",
    "        dtrain=dtrain,\n",
    "        evals=watchlist,\n",
    "        num_boost_round=args.num_round,\n",
    "        early_stopping_rounds=args.early_stopping_rounds,\n",
    "        model_dir=args.model_dir,\n",
    "        output_data_dir=args.output_data_dir,\n",
    "        GetFIFlg=args.GetFIFlg,\n",
    "        GetTestScoreFlg=args.GetTestScoreFlg,\n",
    "        GetTestPredFlg=args.GetTestPredFlg)\n",
    "\n",
    "    if len(sm_hosts) > 1:\n",
    "        # Wait until all hosts are able to find each other\n",
    "        entry_point._wait_hostname_resolution()\n",
    "\n",
    "        # Execute training function after initializing rabit.\n",
    "        distributed.rabit_run(\n",
    "            exec_fun=_xgb_train,\n",
    "            args=xgb_train_args,\n",
    "            include_in_training=(dtrain is not None),\n",
    "            hosts=sm_hosts,\n",
    "            current_host=sm_current_host,\n",
    "            update_rabit_args=True\n",
    "        )\n",
    "    else:\n",
    "        # If single node training, call training method directly.\n",
    "        if dtrain:\n",
    "            xgb_train_args['is_master'] = True\n",
    "            _xgb_train(**xgb_train_args)\n",
    "        else:\n",
    "            raise ValueError(\"Training channel must have data to train model.\")\n",
    "\n",
    "#not clear what's this for multi-node training?\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize and return fitted model.\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the _xgb_train method\n",
    "    \"\"\"\n",
    "    model_file = 'xgboost-model'\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), 'rb'))\n",
    "    return booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ModelTraining_Gini_named_AUC_EvalMetric.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ModelTraining_Gini_named_AUC_EvalMetric.py\n",
    "#ModelTraining_Gini_named_AUC_EvalMetric.py uses XGBoost training with custom evaluation metric - gini, but the name of the custom function inside the script is auc, \n",
    "# no need for custom image_uri in XGBoost and metric definitions.\n",
    "\n",
    "\n",
    "#  Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "#  You may not use this file except in compliance with the License.\n",
    "#  A copy of the License is located at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  or in the \"license\" file accompanying this file. This file is distributed\n",
    "#  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "#  express or implied. See the License for the specific language governing\n",
    "#  permissions and limitations under the License.\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from sagemaker_containers import entry_point\n",
    "from sagemaker_xgboost_container.data_utils import get_dmatrix\n",
    "from sagemaker_xgboost_container import distributed\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auc(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "def auc_xgb(pred, y):\n",
    "    y = y.get_label()\n",
    "    return 'auc', auc(y, pred) / auc(y, y)\n",
    "\n",
    "def _xgb_train(params, dtrain, evals, num_boost_round, early_stopping_rounds, model_dir, output_data_dir, GetFIFlg,GetTestScoreFlg,GetTestPredFlg, is_master):\n",
    "    \"\"\"Run xgb train on arguments given with rabit initialized.\n",
    "\n",
    "    This is our rabit execution function.\n",
    "\n",
    "    :param args_dict: Argument dictionary used to run xgb.train().\n",
    "    :param is_master: True if current node is master host in distributed training,\n",
    "                        or is running single node training job.\n",
    "                        Note that rabit_run will include this argument.\n",
    "    \"\"\"\n",
    "    progress = dict()\n",
    "    booster = xgb.train(params=params,\n",
    "                        dtrain=dtrain,\n",
    "                        evals=evals,\n",
    "                        feval=auc_xgb,\n",
    "                        maximize=True,\n",
    "                        num_boost_round=num_boost_round,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        evals_result=progress,\n",
    "                        verbose_eval=100)\n",
    "    \n",
    "    print('Eval results')    \n",
    "    train_error=progress['train']['auc']\n",
    "    eval_error=progress['validation']['auc']\n",
    "    results_pd=pd.DataFrame({'train':train_error,'valid':eval_error},columns=['train','valid'])\n",
    "    \n",
    "    \n",
    "    #feature importance\n",
    "    if GetFIFlg=='Y':\n",
    "        fi_weight =booster.get_score(importance_type='weight')\n",
    "        fi_gain = booster.get_score(importance_type='gain')\n",
    "        fi_cover= booster.get_score(importance_type='cover')\n",
    "        fi_weight_pd = pd.DataFrame(fi_weight.items(),columns=['feature','weight'])\n",
    "        fi_gain_pd = pd.DataFrame(fi_gain.items(),columns=['feature','gain'])\n",
    "        fi_cover_pd = pd.DataFrame(fi_cover.items(),columns=['feature','cover'])\n",
    "        fi_pd=pd.merge(fi_gain_pd, fi_weight_pd, on='feature', how='inner')\n",
    "        fi_pd=pd.merge(fi_pd, fi_cover_pd, on='feature', how='inner')\n",
    "\n",
    "    #Prediction on test data ...\n",
    "    if 'Y' in (GetTestScoreFlg,GetTestPredFlg):\n",
    "        df_prediction=pd.DataFrame()\n",
    "        df_prediction['actual']=dtest.get_label()\n",
    "        df_prediction['pred']=booster.predict(dtest)\n",
    "   \n",
    "        #Test scores from test prediction  It's a custom output, no need to use auc in the name \n",
    "        df_score = pd.DataFrame()\n",
    "        df_score['gini-test']=[auc(df_prediction['actual'], df_prediction['pred'])/auc(df_prediction['actual'], df_prediction['actual'])]\n",
    "    \n",
    "    if is_master:\n",
    "        model_location = model_dir + '/xgboost-model'\n",
    "        pkl.dump(booster, open(model_location, 'wb'))\n",
    "        logging.info(\"Stored trained model at {}\".format(model_location))\n",
    "        \n",
    "        if not os.path.exists(output_data_dir):\n",
    "            os.makedirs(output_data_dir)\n",
    "\n",
    "        result_location = os.path.join(output_data_dir, 'eval_results.csv')\n",
    "        print('Saving eval results at {}'.format(result_location))\n",
    "        logging.info('Saving eval results at {}'.format(result_location))\n",
    "        results_pd.to_csv(result_location, header=True, index=False)\n",
    "        \n",
    "        if GetFIFlg=='Y':\n",
    "            fi_location = os.path.join(output_data_dir, 'fi.csv')\n",
    "            print('Saving feature importance at {}'.format(fi_location))\n",
    "            logging.info('Saving feature importance at {}'.format(fi_location))\n",
    "            fi_pd.to_csv(fi_location, header=True, index=False)\n",
    "        \n",
    "        if GetTestPredFlg=='Y':\n",
    "            predictions_location = os.path.join(output_data_dir, 'test_predictions.csv')\n",
    "            print('Saving test predictions at {}'.format(predictions_location))\n",
    "            logging.info('Saving test predictions at {}'.format(predictions_location))\n",
    "            df_prediction.to_csv(predictions_location, header=True, index=False)\n",
    "            \n",
    "        if GetTestScoreFlg=='Y':        \n",
    "            test_score_location = os.path.join(output_data_dir, 'test_score.csv')\n",
    "            print('Saving test score  at {}'.format(test_score_location))\n",
    "            logging.info('Saving test score  at {}'.format(test_score_location))        \n",
    "            df_score.to_csv(test_score_location, header=True, index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters are described here.\n",
    "    parser.add_argument('--max_depth', type=int,)\n",
    "    parser.add_argument('--eta', type=float)\n",
    "    parser.add_argument('--objective', type=str)\n",
    "    parser.add_argument('--num_round', type=int)\n",
    "\n",
    "    parser.add_argument('--early_stopping_rounds', type=int)\n",
    "    parser.add_argument('--booster', type=str)\n",
    "    #parser.add_argument('--eval_metric', type=str)\n",
    "    parser.add_argument('--seed', type=int, default=42)\n",
    "    parser.add_argument('--scale_pos_weight', type=float)\n",
    "    parser.add_argument('--colsample_bylevel', type=float)\n",
    "    parser.add_argument('--colsample_bytree', type=float)\n",
    "    parser.add_argument('--subsample', type=float)\n",
    "    parser.add_argument('--max_delta_step', type=int)\n",
    "    \n",
    "    \n",
    "    parser.add_argument('--GetFIFlg', type=str, default='N')\n",
    "    parser.add_argument('--GetTestScoreFlg', type=str, default='N')\n",
    "    parser.add_argument('--GetTestPredFlg', type=str, default='N')            \n",
    "            \n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    \n",
    "    parser.add_argument('--output_data_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    parser.add_argument('--sm_hosts', type=str, default=os.environ.get('SM_HOSTS'))\n",
    "    parser.add_argument('--sm_current_host', type=str, default=os.environ.get('SM_CURRENT_HOST'))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Get SageMaker host information from runtime environment variables\n",
    "    sm_hosts = json.loads(args.sm_hosts)\n",
    "    sm_current_host = args.sm_current_host\n",
    "\n",
    "    dtrain = get_dmatrix(args.train, 'csv')\n",
    "    dval = get_dmatrix(args.validation, 'csv')\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'validation')] if dval is not None else [(dtrain, 'train')]\n",
    "\n",
    "      \n",
    "    dtest = get_dmatrix(args.test, 'csv')\n",
    "    if not(dtest):\n",
    "        if ((args.GetTestScoreFlg=='Y') | (args.GetTestPredFlg=='Y')):\n",
    "            raise Exception('Please provide test data in a test channel for prediction and scores or set GetTestScoreFlg and GetTestPredFlg to N')\n",
    "            \n",
    "    train_hp = {\n",
    "        'max_depth': args.max_depth,\n",
    "        'eta': args.eta,\n",
    "        'objective': args.objective,\n",
    "        'booster': args.booster,\n",
    "        'seed': args.seed,\n",
    "        #'eval_metric':args.eval_metric,\n",
    "        'disable_default_eval_metric': '1',\n",
    "        'scale_pos_weight':args.scale_pos_weight,\n",
    "        'colsample_bylevel': args.colsample_bylevel,\n",
    "        'colsample_bytree': args.colsample_bytree,\n",
    "        'subsample': args.subsample,\n",
    "        'max_delta_step':args.max_delta_step\n",
    "        }\n",
    "\n",
    "    xgb_train_args = dict(\n",
    "        params=train_hp,\n",
    "        dtrain=dtrain,\n",
    "        evals=watchlist,\n",
    "        num_boost_round=args.num_round,\n",
    "        early_stopping_rounds=args.early_stopping_rounds,\n",
    "        model_dir=args.model_dir,\n",
    "        output_data_dir=args.output_data_dir,\n",
    "        GetFIFlg=args.GetFIFlg,\n",
    "        GetTestScoreFlg=args.GetTestScoreFlg,\n",
    "        GetTestPredFlg=args.GetTestPredFlg)\n",
    "\n",
    "    if len(sm_hosts) > 1:\n",
    "        # Wait until all hosts are able to find each other\n",
    "        entry_point._wait_hostname_resolution()\n",
    "\n",
    "        # Execute training function after initializing rabit.\n",
    "        distributed.rabit_run(\n",
    "            exec_fun=_xgb_train,\n",
    "            args=xgb_train_args,\n",
    "            include_in_training=(dtrain is not None),\n",
    "            hosts=sm_hosts,\n",
    "            current_host=sm_current_host,\n",
    "            update_rabit_args=True\n",
    "        )\n",
    "    else:\n",
    "        # If single node training, call training method directly.\n",
    "        if dtrain:\n",
    "            xgb_train_args['is_master'] = True\n",
    "            _xgb_train(**xgb_train_args)\n",
    "        else:\n",
    "            raise ValueError(\"Training channel must have data to train model.\")\n",
    "\n",
    "#not clear what's this for multi-node training?\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize and return fitted model.\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the _xgb_train method\n",
    "    \"\"\"\n",
    "    model_file = 'xgboost-model'\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), 'rb'))\n",
    "    return booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ModelTraining_Gini_EvalMetric.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ModelTraining_Gini_EvalMetric.py\n",
    "#ModelTraining_Gini_EvalMetric.py uses XGBoost training with custom evaluation metric - gini. Use custom image_uri and metric defnitions.\n",
    "\n",
    "#  Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "#  You may not use this file except in compliance with the License.\n",
    "#  A copy of the License is located at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  or in the \"license\" file accompanying this file. This file is distributed\n",
    "#  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "#  express or implied. See the License for the specific language governing\n",
    "#  permissions and limitations under the License.\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from sagemaker_containers import entry_point\n",
    "from sagemaker_xgboost_container.data_utils import get_dmatrix\n",
    "from sagemaker_xgboost_container import distributed\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def gini(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "def gini_xgb(pred, y):\n",
    "    y = y.get_label()\n",
    "    return 'gini', gini(y, pred) / gini(y, y)\n",
    "\n",
    "def _xgb_train(params, dtrain, evals, num_boost_round, early_stopping_rounds, model_dir, output_data_dir, GetFIFlg,GetTestScoreFlg,GetTestPredFlg, is_master):\n",
    "    \"\"\"Run xgb train on arguments given with rabit initialized.\n",
    "\n",
    "    This is our rabit execution function.\n",
    "\n",
    "    :param args_dict: Argument dictionary used to run xgb.train().\n",
    "    :param is_master: True if current node is master host in distributed training,\n",
    "                        or is running single node training job.\n",
    "                        Note that rabit_run will include this argument.\n",
    "    \"\"\"\n",
    "    progress = dict()\n",
    "    booster = xgb.train(params=params,\n",
    "                        dtrain=dtrain,\n",
    "                        evals=evals,\n",
    "                        feval=gini_xgb,\n",
    "                        maximize=True,\n",
    "                        num_boost_round=num_boost_round,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        evals_result=progress,\n",
    "                        verbose_eval=100)\n",
    "    \n",
    "    print('Eval results')    \n",
    "    train_error=progress['train']['gini']\n",
    "    eval_error=progress['validation']['gini']\n",
    "    results_pd=pd.DataFrame({'train':train_error,'valid':eval_error},columns=['train','valid'])\n",
    "    \n",
    "    \n",
    "    #feature importance\n",
    "    if GetFIFlg=='Y':\n",
    "        fi_weight =booster.get_score(importance_type='weight')\n",
    "        fi_gain = booster.get_score(importance_type='gain')\n",
    "        fi_cover= booster.get_score(importance_type='cover')\n",
    "        fi_weight_pd = pd.DataFrame(fi_weight.items(),columns=['feature','weight'])\n",
    "        fi_gain_pd = pd.DataFrame(fi_gain.items(),columns=['feature','gain'])\n",
    "        fi_cover_pd = pd.DataFrame(fi_cover.items(),columns=['feature','cover'])\n",
    "        fi_pd=pd.merge(fi_gain_pd, fi_weight_pd, on='feature', how='inner')\n",
    "        fi_pd=pd.merge(fi_pd, fi_cover_pd, on='feature', how='inner')\n",
    "\n",
    "    #Prediction on test data ...\n",
    "    if 'Y' in (GetTestScoreFlg,GetTestPredFlg):\n",
    "        df_prediction=pd.DataFrame()\n",
    "        df_prediction['actual']=dtest.get_label()\n",
    "        df_prediction['pred']=booster.predict(dtest)\n",
    "   \n",
    "        #Test scores from test prediction   \n",
    "        df_score = pd.DataFrame()\n",
    "        df_score['gini-test']=[gini(df_prediction['actual'], df_prediction['pred'])/gini(df_prediction['actual'],df_prediction['actual'])]\n",
    "        \n",
    "    \n",
    "    if is_master:\n",
    "        model_location = model_dir + '/xgboost-model'\n",
    "        pkl.dump(booster, open(model_location, 'wb'))\n",
    "        logging.info(\"Stored trained model at {}\".format(model_location))\n",
    "        \n",
    "        if not os.path.exists(output_data_dir):\n",
    "            os.makedirs(output_data_dir)\n",
    "\n",
    "        result_location = os.path.join(output_data_dir, 'eval_results.csv')\n",
    "        print('Saving eval results at {}'.format(result_location))\n",
    "        logging.info('Saving eval results at {}'.format(result_location))\n",
    "        results_pd.to_csv(result_location, header=True, index=False)\n",
    "        \n",
    "        if GetFIFlg=='Y':\n",
    "            fi_location = os.path.join(output_data_dir, 'fi.csv')\n",
    "            print('Saving feature importance at {}'.format(fi_location))\n",
    "            logging.info('Saving feature importance at {}'.format(fi_location))\n",
    "            fi_pd.to_csv(fi_location, header=True, index=False)\n",
    "        \n",
    "        if GetTestPredFlg=='Y':\n",
    "            predictions_location = os.path.join(output_data_dir, 'test_predictions.csv')\n",
    "            print('Saving test predictions at {}'.format(predictions_location))\n",
    "            logging.info('Saving test predictions at {}'.format(predictions_location))\n",
    "            df_prediction.to_csv(predictions_location, header=True, index=False)\n",
    "            \n",
    "        if GetTestScoreFlg=='Y':        \n",
    "            test_score_location = os.path.join(output_data_dir, 'test_score.csv')\n",
    "            print('Saving test score  at {}'.format(test_score_location))\n",
    "            logging.info('Saving test score  at {}'.format(test_score_location))        \n",
    "            df_score.to_csv(test_score_location, header=True, index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters are described here.\n",
    "    parser.add_argument('--max_depth', type=int,)\n",
    "    parser.add_argument('--eta', type=float)\n",
    "    parser.add_argument('--objective', type=str)\n",
    "    parser.add_argument('--num_round', type=int)\n",
    "\n",
    "    parser.add_argument('--early_stopping_rounds', type=int)\n",
    "    parser.add_argument('--booster', type=str)\n",
    "    #parser.add_argument('--eval_metric', type=str)\n",
    "    parser.add_argument('--seed', type=int, default=42)\n",
    "    parser.add_argument('--scale_pos_weight', type=float)\n",
    "    parser.add_argument('--colsample_bylevel', type=float)\n",
    "    parser.add_argument('--colsample_bytree', type=float)\n",
    "    parser.add_argument('--subsample', type=float)\n",
    "    parser.add_argument('--max_delta_step', type=int)\n",
    "    \n",
    "    \n",
    "    parser.add_argument('--GetFIFlg', type=str, default='N')\n",
    "    parser.add_argument('--GetTestScoreFlg', type=str, default='N')\n",
    "    parser.add_argument('--GetTestPredFlg', type=str, default='N')            \n",
    "            \n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    \n",
    "    parser.add_argument('--output_data_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    parser.add_argument('--sm_hosts', type=str, default=os.environ.get('SM_HOSTS'))\n",
    "    parser.add_argument('--sm_current_host', type=str, default=os.environ.get('SM_CURRENT_HOST'))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Get SageMaker host information from runtime environment variables\n",
    "    sm_hosts = json.loads(args.sm_hosts)\n",
    "    sm_current_host = args.sm_current_host\n",
    "\n",
    "    dtrain = get_dmatrix(args.train, 'csv')\n",
    "    dval = get_dmatrix(args.validation, 'csv')\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'validation')] if dval is not None else [(dtrain, 'train')]\n",
    "\n",
    "      \n",
    "    dtest = get_dmatrix(args.test, 'csv')\n",
    "    if not(dtest):\n",
    "        if ((args.GetTestScoreFlg=='Y') | (args.GetTestPredFlg=='Y')):\n",
    "            raise Exception('Please provide test data in a test channel for prediction and scores or set GetTestScoreFlg and GetTestPredFlg to N')\n",
    "            \n",
    "    train_hp = {\n",
    "        'max_depth': args.max_depth,\n",
    "        'eta': args.eta,\n",
    "        'objective': args.objective,\n",
    "        'booster': args.booster,\n",
    "        'seed': args.seed,\n",
    "        #'eval_metric':args.eval_metric,\n",
    "        'disable_default_eval_metric': '1',\n",
    "        'scale_pos_weight':args.scale_pos_weight,\n",
    "        'colsample_bylevel': args.colsample_bylevel,\n",
    "        'colsample_bytree': args.colsample_bytree,\n",
    "        'subsample': args.subsample,\n",
    "        'max_delta_step':args.max_delta_step\n",
    "        }\n",
    "\n",
    "    xgb_train_args = dict(\n",
    "        params=train_hp,\n",
    "        dtrain=dtrain,\n",
    "        evals=watchlist,\n",
    "        num_boost_round=args.num_round,\n",
    "        early_stopping_rounds=args.early_stopping_rounds,\n",
    "        model_dir=args.model_dir,\n",
    "        output_data_dir=args.output_data_dir,\n",
    "        GetFIFlg=args.GetFIFlg,\n",
    "        GetTestScoreFlg=args.GetTestScoreFlg,\n",
    "        GetTestPredFlg=args.GetTestPredFlg)\n",
    "\n",
    "    if len(sm_hosts) > 1:\n",
    "        # Wait until all hosts are able to find each other\n",
    "        entry_point._wait_hostname_resolution()\n",
    "\n",
    "        # Execute training function after initializing rabit.\n",
    "        distributed.rabit_run(\n",
    "            exec_fun=_xgb_train,\n",
    "            args=xgb_train_args,\n",
    "            include_in_training=(dtrain is not None),\n",
    "            hosts=sm_hosts,\n",
    "            current_host=sm_current_host,\n",
    "            update_rabit_args=True\n",
    "        )\n",
    "    else:\n",
    "        # If single node training, call training method directly.\n",
    "        if dtrain:\n",
    "            xgb_train_args['is_master'] = True\n",
    "            _xgb_train(**xgb_train_args)\n",
    "        else:\n",
    "            raise ValueError(\"Training channel must have data to train model.\")\n",
    "\n",
    "#not clear what's this for multi-node training?\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize and return fitted model.\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the _xgb_train method\n",
    "    \"\"\"\n",
    "    model_file = 'xgboost-model'\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), 'rb'))\n",
    "    return booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>objective</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>booster</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>eta</th>\n",
       "      <th>subsample</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel-0</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaseModel-1</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaseModel-2</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BaseModel-3</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaseModel-4</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>customer_cnt_active_policies</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>replacementcostdwellingind</td>\n",
       "      <td>pipe_froze_3_blk</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>poolind</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>plumb_leak_3_blk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Model3-5</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Model3-6</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Model3-7</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Model3-8</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Model3-9</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>auc</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>sqft</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model        objective eval_metric booster  scale_pos_weight  \\\n",
       "0    BaseModel-0  binary:logistic         auc  gbtree               0.3   \n",
       "1    BaseModel-1  binary:logistic         auc  gbtree               0.3   \n",
       "2    BaseModel-2  binary:logistic         auc  gbtree               0.3   \n",
       "3    BaseModel-3  binary:logistic         auc  gbtree               0.3   \n",
       "4    BaseModel-4  binary:logistic         auc  gbtree               0.3   \n",
       "..           ...              ...         ...     ...               ...   \n",
       "115     Model3-5  binary:logistic         auc  gbtree               0.3   \n",
       "116     Model3-6  binary:logistic         auc  gbtree               0.3   \n",
       "117     Model3-7  binary:logistic         auc  gbtree               0.3   \n",
       "118     Model3-8  binary:logistic         auc  gbtree               0.3   \n",
       "119     Model3-9  binary:logistic         auc  gbtree               0.3   \n",
       "\n",
       "     colsample_bylevel  colsample_bytree   eta  subsample  max_depth  ...  \\\n",
       "0                  0.8               0.8  0.04        0.6          6  ...   \n",
       "1                  0.8               0.8  0.04        0.6          6  ...   \n",
       "2                  0.8               0.8  0.04        0.6          6  ...   \n",
       "3                  0.8               0.8  0.04        0.6          6  ...   \n",
       "4                  0.8               0.8  0.04        0.6          6  ...   \n",
       "..                 ...               ...   ...        ...        ...  ...   \n",
       "115                0.8               0.8  0.04        0.6          6  ...   \n",
       "116                0.8               0.8  0.04        0.6          6  ...   \n",
       "117                0.8               0.8  0.04        0.6          6  ...   \n",
       "118                0.8               0.8  0.04        0.6          6  ...   \n",
       "119                0.8               0.8  0.04        0.6          6  ...   \n",
       "\n",
       "       F3                            F4                F5  \\\n",
       "0    sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "1    sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "2    sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "3    sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "4    sqft  customer_cnt_active_policies    usagetype_encd   \n",
       "..    ...                           ...               ...   \n",
       "115  sqft                usagetype_encd  water_risk_3_blk   \n",
       "116  sqft                usagetype_encd  water_risk_3_blk   \n",
       "117  sqft                usagetype_encd  water_risk_3_blk   \n",
       "118  sqft                usagetype_encd  water_risk_3_blk   \n",
       "119  sqft                usagetype_encd  water_risk_3_blk   \n",
       "\n",
       "                             F6                F7           F8  \\\n",
       "0    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "1    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "2    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "3    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "4    replacementcostdwellingind  pipe_froze_3_blk  landlordind   \n",
       "..                          ...               ...          ...   \n",
       "115                         NaN               NaN          NaN   \n",
       "116                         NaN               NaN          NaN   \n",
       "117                         NaN               NaN          NaN   \n",
       "118                         NaN               NaN          NaN   \n",
       "119                         NaN               NaN          NaN   \n",
       "\n",
       "                   F9      F10         F11               F12  \n",
       "0    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "1    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "2    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "3    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "4    water_risk_3_blk  poolind  cova_limit  plumb_leak_3_blk  \n",
       "..                ...      ...         ...               ...  \n",
       "115               NaN      NaN         NaN               NaN  \n",
       "116               NaN      NaN         NaN               NaN  \n",
       "117               NaN      NaN         NaN               NaN  \n",
       "118               NaN      NaN         NaN               NaN  \n",
       "119               NaN      NaN         NaN               NaN  \n",
       "\n",
       "[120 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_from_preprocessed_data=preprocessed_data['Model'].tolist()\n",
    "models_from_model_params=model_params['Model'].tolist()\n",
    "if len([x for x in models_from_preprocessed_data if x not in models_from_model_params])!=0:\n",
    "    raise Exception('Different set of models in preprocessed_data and parametersets!')\n",
    "#using merge because, in general, we can have different number of rows in each dataframe - folds in data and different sets of params\n",
    "data_for_training=pd.merge(model_params, preprocessed_data, on='Model', how='inner')\n",
    "data_for_training['Model']=data_for_training['Model']+'-'+data_for_training['fold'].astype(str)\n",
    "data_for_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use AWS SageMaker montoring system, charts and AWS SageMaker experiment then custom metrics should be registered. The metrics work only with a custom XGBoost image. See more detail at the top how to create it.\n",
    "Comment using metric_definitions and image_uri in the next cell (look for xgb_script_mode_estimator = XGBoost) if you are Ok with the custom script output and do not use/need AWS SageMaker monitoring features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if entry_point=='ModelTraining_Gini_EvalMetric.py':\n",
    "    #[0]#011train-gini:0.00612#011validation-gini:0.01274\n",
    "    metric_definitions = [\n",
    "    {\n",
    "        'Name': 'train-gini',\n",
    "        'Regex': '.*\\\\[[0-9]+\\\\].*#011train-gini:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'\n",
    "    },    \n",
    "    {\n",
    "        'Name': 'validation-gini',\n",
    "        'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-gini:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'\n",
    "    }\n",
    "] \n",
    "    image_uri=custom_image_uri\n",
    "    score='gini'\n",
    "else:\n",
    "    metric_definitions = []\n",
    "    image_uri=''\n",
    "    score='auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-0-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training job for  BaseModel-0-0 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: BaseModel-0-0-2021-05-30-04-01-57\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-1-1\n",
      "Creating training job for  BaseModel-1-1 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: BaseModel-1-1-2021-05-30-04-01-58\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-2-2\n",
      "Creating training job for  BaseModel-2-2 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: BaseModel-2-2-2021-05-30-04-02-01\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-3-3\n",
      "Creating training job for  BaseModel-3-3 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: BaseModel-3-3-2021-05-30-04-02-03\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-4-4\n",
      "Creating training job for  BaseModel-4-4 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: BaseModel-4-4-2021-05-30-04-02-05\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-5-5\n",
      "Creating training job for  BaseModel-5-5 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: BaseModel-5-5-2021-05-30-04-02-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-6-6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training job for  BaseModel-6-6 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: BaseModel-6-6-2021-05-30-04-02-09\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-7-7\n",
      "Creating training job for  BaseModel-7-7 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: BaseModel-7-7-2021-05-30-04-02-10\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-8-8\n",
      "Creating training job for  BaseModel-8-8 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: BaseModel-8-8-2021-05-30-04-02-11\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel-9-9\n",
      "Creating training job for  BaseModel-9-9 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: BaseModel-9-9-2021-05-30-04-02-13\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-0-10\n",
      "Creating training job for  NoPlumbLeak-0-10 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-0-10-2021-05-30-04-02-15\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-1-11\n",
      "Creating training job for  NoPlumbLeak-1-11 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-1-11-2021-05-30-04-02-17\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-2-12\n",
      "Creating training job for  NoPlumbLeak-2-12 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-2-12-2021-05-30-04-02-18\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-3-13\n",
      "Creating training job for  NoPlumbLeak-3-13 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-3-13-2021-05-30-04-02-21\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-4-14\n",
      "Creating training job for  NoPlumbLeak-4-14 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-4-14-2021-05-30-04-02-23\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-5-15\n",
      "Creating training job for  NoPlumbLeak-5-15 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-5-15-2021-05-30-04-02-26\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-6-16\n",
      "Creating training job for  NoPlumbLeak-6-16 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-6-16-2021-05-30-04-02-27\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-7-17\n",
      "Creating training job for  NoPlumbLeak-7-17 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-7-17-2021-05-30-04-02-28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-8-18\n",
      "Creating training job for  NoPlumbLeak-8-18 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-8-18-2021-05-30-04-02-30\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPlumbLeak-9-19\n",
      "Creating training job for  NoPlumbLeak-9-19 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPlumbLeak-9-19-2021-05-30-04-02-32\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-0-20\n",
      "Creating training job for  Nocovalimit-0-20 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-0-20-2021-05-30-04-02-36\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-1-21\n",
      "Creating training job for  Nocovalimit-1-21 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-1-21-2021-05-30-04-02-37\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-2-22\n",
      "Creating training job for  Nocovalimit-2-22 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-2-22-2021-05-30-04-02-40\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-3-23\n",
      "Creating training job for  Nocovalimit-3-23 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-3-23-2021-05-30-04-02-42\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-4-24\n",
      "Creating training job for  Nocovalimit-4-24 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-4-24-2021-05-30-04-02-43\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-5-25\n",
      "Creating training job for  Nocovalimit-5-25 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-5-25-2021-05-30-04-02-45\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-6-26\n",
      "Creating training job for  Nocovalimit-6-26 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-6-26-2021-05-30-04-02-48\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-7-27\n",
      "Creating training job for  Nocovalimit-7-27 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-7-27-2021-05-30-04-02-50\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-8-28\n",
      "Creating training job for  Nocovalimit-8-28 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-8-28-2021-05-30-04-02-54\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nocovalimit-9-29\n",
      "Creating training job for  Nocovalimit-9-29 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nocovalimit-9-29-2021-05-30-04-02-55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-0-30\n",
      "There is no slot to train  Nopool-0-30 model. Waiting...\n",
      "......................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-8-18-2021-05-30-04-02-30  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-0-30 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-0-30-2021-05-30-04-11-39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-1-31\n",
      "There is no slot to train  Nopool-1-31 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-3-3-2021-05-30-04-02-03  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-1-31 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-1-31-2021-05-30-04-11-52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-2-32\n",
      "There is no slot to train  Nopool-2-32 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-3-13-2021-05-30-04-02-21  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-2-32 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-2-32-2021-05-30-04-12-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-3-33\n",
      "There is no slot to train  Nopool-3-33 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-8-8-2021-05-30-04-02-11  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-3-33 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-3-33-2021-05-30-04-12-20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-4-34\n",
      "There is no slot to train  Nopool-4-34 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-7-7-2021-05-30-04-02-10  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-4-34 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-4-34-2021-05-30-04-12-34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-5-35\n",
      "There is no slot to train  Nopool-5-35 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-5-5-2021-05-30-04-02-07  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-5-35 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-5-35-2021-05-30-04-12-47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-6-36\n",
      "There is no slot to train  Nopool-6-36 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-9-9-2021-05-30-04-02-13  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-6-36 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-6-36-2021-05-30-04-13-00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-7-37\n",
      "There is no slot to train  Nopool-7-37 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-0-10-2021-05-30-04-02-15  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-7-37 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-7-37-2021-05-30-04-13-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-8-38\n",
      "There is no slot to train  Nopool-8-38 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-5-15-2021-05-30-04-02-26  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-8-38 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-8-38-2021-05-30-04-13-27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nopool-9-39\n",
      "There is no slot to train  Nopool-9-39 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-4-14-2021-05-30-04-02-23  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nopool-9-39 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nopool-9-39-2021-05-30-04-13-40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-0-40\n",
      "There is no slot to train  NoWaterRisk-0-40 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-1-1-2021-05-30-04-01-58  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-0-40 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-0-40-2021-05-30-04-13-53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-1-41\n",
      "There is no slot to train  NoWaterRisk-1-41 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-7-17-2021-05-30-04-02-28  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-1-41 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-1-41-2021-05-30-04-14-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-2-42\n",
      "There is no slot to train  NoWaterRisk-2-42 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-0-0-2021-05-30-04-01-57  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-2-42 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-2-42-2021-05-30-04-14-18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-3-43\n",
      "There is no slot to train  NoWaterRisk-3-43 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-9-19-2021-05-30-04-02-32  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-3-43 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-3-43-2021-05-30-04-14-32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-4-44\n",
      "There is no slot to train  NoWaterRisk-4-44 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-1-21-2021-05-30-04-02-37  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-4-44 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-4-44-2021-05-30-04-14-45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-5-45\n",
      "There is no slot to train  NoWaterRisk-5-45 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-2-22-2021-05-30-04-02-40  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-5-45 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-5-45-2021-05-30-04-14-59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-6-46\n",
      "There is no slot to train  NoWaterRisk-6-46 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-6-6-2021-05-30-04-02-09  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-6-46 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-6-46-2021-05-30-04-15-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-7-47\n",
      "There is no slot to train  NoWaterRisk-7-47 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-1-11-2021-05-30-04-02-17  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-7-47 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-7-47-2021-05-30-04-15-23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-8-48\n",
      "There is no slot to train  NoWaterRisk-8-48 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-3-23-2021-05-30-04-02-42  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-8-48 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-8-48-2021-05-30-04-15-36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoWaterRisk-9-49\n",
      "There is no slot to train  NoWaterRisk-9-49 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-4-24-2021-05-30-04-02-43  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoWaterRisk-9-49 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: NoWaterRisk-9-49-2021-05-30-04-15-49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-0-50\n",
      "There is no slot to train  Nolandlord-0-50 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-2-2-2021-05-30-04-02-01  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-0-50 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nolandlord-0-50-2021-05-30-04-16-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-1-51\n",
      "There is no slot to train  Nolandlord-1-51 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job BaseModel-4-4-2021-05-30-04-02-05  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-1-51 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nolandlord-1-51-2021-05-30-04-16-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-2-52\n",
      "There is no slot to train  Nolandlord-2-52 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-2-12-2021-05-30-04-02-18  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-2-52 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nolandlord-2-52-2021-05-30-04-16-25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-3-53\n",
      "There is no slot to train  Nolandlord-3-53 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-0-20-2021-05-30-04-02-36  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-3-53 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nolandlord-3-53-2021-05-30-04-16-38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-4-54\n",
      "There is no slot to train  Nolandlord-4-54 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-5-25-2021-05-30-04-02-45  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-4-54 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nolandlord-4-54-2021-05-30-04-16-50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-5-55\n",
      "There is no slot to train  Nolandlord-5-55 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoPlumbLeak-6-16-2021-05-30-04-02-27  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-5-55 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nolandlord-5-55-2021-05-30-04-17-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-6-56\n",
      "There is no slot to train  Nolandlord-6-56 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-6-26-2021-05-30-04-02-48  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-6-56 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nolandlord-6-56-2021-05-30-04-17-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-7-57\n",
      "There is no slot to train  Nolandlord-7-57 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-7-27-2021-05-30-04-02-50  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-7-57 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nolandlord-7-57-2021-05-30-04-17-26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-8-58\n",
      "There is no slot to train  Nolandlord-8-58 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-8-28-2021-05-30-04-02-54  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-8-58 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: Nolandlord-8-58-2021-05-30-04-17-39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolandlord-9-59\n",
      "There is no slot to train  Nolandlord-9-59 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nocovalimit-9-29-2021-05-30-04-02-55  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nolandlord-9-59 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nolandlord-9-59-2021-05-30-04-17-51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-0-60\n",
      "There is no slot to train  NoPipeFroze-0-60 model. Waiting...\n",
      "........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-1-31-2021-05-30-04-11-52  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-0-60 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-0-60-2021-05-30-04-20-52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-1-61\n",
      "There is no slot to train  NoPipeFroze-1-61 model. Waiting...\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-0-30-2021-05-30-04-11-39  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-1-61 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-1-61-2021-05-30-04-21-22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-2-62\n",
      "There is no slot to train  NoPipeFroze-2-62 model. Waiting...\n",
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-3-33-2021-05-30-04-12-20  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-2-62 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-2-62-2021-05-30-04-22-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-3-63\n",
      "There is no slot to train  NoPipeFroze-3-63 model. Waiting...\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-2-32-2021-05-30-04-12-07  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-3-63 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-3-63-2021-05-30-04-22-39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-4-64\n",
      "There is no slot to train  NoPipeFroze-4-64 model. Waiting...\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-8-38-2021-05-30-04-13-27  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-4-64 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-4-64-2021-05-30-04-23-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-5-65\n",
      "There is no slot to train  NoPipeFroze-5-65 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-9-39-2021-05-30-04-13-40  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-5-65 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-5-65-2021-05-30-04-23-22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-6-66\n",
      "There is no slot to train  NoPipeFroze-6-66 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-4-34-2021-05-30-04-12-34  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-6-66 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-6-66-2021-05-30-04-23-34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-7-67\n",
      "There is no slot to train  NoPipeFroze-7-67 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-5-35-2021-05-30-04-12-47  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-7-67 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-7-67-2021-05-30-04-23-46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-8-68\n",
      "There is no slot to train  NoPipeFroze-8-68 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-0-40-2021-05-30-04-13-53  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-8-68 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-8-68-2021-05-30-04-23-59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoPipeFroze-9-69\n",
      "There is no slot to train  NoPipeFroze-9-69 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-1-41-2021-05-30-04-14-06  is Completed\n",
      "Continue training...\n",
      "Creating training job for  NoPipeFroze-9-69 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: NoPipeFroze-9-69-2021-05-30-04-24-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-0-70\n",
      "There is no slot to train  Norplcostdwel-0-70 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-2-42-2021-05-30-04-14-18  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-0-70 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-0-70-2021-05-30-04-24-23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-1-71\n",
      "There is no slot to train  Norplcostdwel-1-71 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-3-43-2021-05-30-04-14-32  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-1-71 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-1-71-2021-05-30-04-24-35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-2-72\n",
      "There is no slot to train  Norplcostdwel-2-72 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-5-45-2021-05-30-04-14-59  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-2-72 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-2-72-2021-05-30-04-24-48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-3-73\n",
      "There is no slot to train  Norplcostdwel-3-73 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-7-37-2021-05-30-04-13-13  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-3-73 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-3-73-2021-05-30-04-25-00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-4-74\n",
      "There is no slot to train  Norplcostdwel-4-74 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-4-44-2021-05-30-04-14-45  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-4-74 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-4-74-2021-05-30-04-25-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-5-75\n",
      "There is no slot to train  Norplcostdwel-5-75 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-6-46-2021-05-30-04-15-11  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-5-75 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-5-75-2021-05-30-04-25-25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-6-76\n",
      "There is no slot to train  Norplcostdwel-6-76 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-7-47-2021-05-30-04-15-23  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-6-76 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-6-76-2021-05-30-04-25-37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-7-77\n",
      "There is no slot to train  Norplcostdwel-7-77 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-8-48-2021-05-30-04-15-36  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-7-77 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-7-77-2021-05-30-04-25-49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-8-78\n",
      "There is no slot to train  Norplcostdwel-8-78 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job NoWaterRisk-9-49-2021-05-30-04-15-49  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-8-78 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-8-78-2021-05-30-04-26-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norplcostdwel-9-79\n",
      "There is no slot to train  Norplcostdwel-9-79 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-0-50-2021-05-30-04-16-02  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Norplcostdwel-9-79 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Norplcostdwel-9-79-2021-05-30-04-26-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-0-80\n",
      "There is no slot to train  Nousagetype-0-80 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-1-51-2021-05-30-04-16-14  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-0-80 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nousagetype-0-80-2021-05-30-04-26-25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-1-81\n",
      "There is no slot to train  Nousagetype-1-81 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-2-52-2021-05-30-04-16-25  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-1-81 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nousagetype-1-81-2021-05-30-04-26-37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-2-82\n",
      "There is no slot to train  Nousagetype-2-82 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-3-53-2021-05-30-04-16-38  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-2-82 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nousagetype-2-82-2021-05-30-04-26-49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-3-83\n",
      "There is no slot to train  Nousagetype-3-83 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-4-54-2021-05-30-04-16-50  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-3-83 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: Nousagetype-3-83-2021-05-30-04-27-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-4-84\n",
      "There is no slot to train  Nousagetype-4-84 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nopool-6-36-2021-05-30-04-13-00  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-4-84 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nousagetype-4-84-2021-05-30-04-27-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-5-85\n",
      "There is no slot to train  Nousagetype-5-85 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-5-55-2021-05-30-04-17-02  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-5-85 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nousagetype-5-85-2021-05-30-04-27-25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-6-86\n",
      "There is no slot to train  Nousagetype-6-86 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-6-56-2021-05-30-04-17-14  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-6-86 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nousagetype-6-86-2021-05-30-04-27-37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-7-87\n",
      "There is no slot to train  Nousagetype-7-87 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-7-57-2021-05-30-04-17-26  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-7-87 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nousagetype-7-87-2021-05-30-04-27-49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-8-88\n",
      "There is no slot to train  Nousagetype-8-88 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-8-58-2021-05-30-04-17-39  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-8-88 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nousagetype-8-88-2021-05-30-04-28-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nousagetype-9-89\n",
      "There is no slot to train  Nousagetype-9-89 model. Waiting...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Nolandlord-9-59-2021-05-30-04-17-51  is Completed\n",
      "Continue training...\n",
      "Creating training job for  Nousagetype-9-89 model\n",
      "{'early_stopping_rounds': 100, 'seed': 42, 'nfold': '10', 'GetFIFlg': 'Y', 'GetTestScoreFlg': 'Y', 'GetTestPredFlg': 'Y', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'booster': 'gbtree', 'scale_pos_weight': 0.3, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'eta': 0.04, 'subsample': 0.6, 'max_depth': 6, 'num_round': 5000, 'fold': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: Nousagetype-9-89-2021-05-30-04-28-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1-0-90\n",
      "There is no slot to train  Model1-0-90 model. Waiting...\n",
      "......."
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ThrottlingException) when calling the DescribeTrainingJob operation (reached max retries: 4): Rate exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6133d03bd58d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mModelFailed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrainingJobName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrainingJobStatus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mdummyFlag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStopOnFailedModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;34m\"\"\"Returns a response from the DescribeTrainingJob API call.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrule_job_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mdescribe_training_job\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m         \"\"\"\n\u001b[0;32m-> 1528\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m     def auto_ml(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ThrottlingException) when calling the DescribeTrainingJob operation (reached max retries: 4): Rate exceeded"
     ]
    }
   ],
   "source": [
    "CntRunningInst = 0\n",
    "\n",
    "processors=list()\n",
    "\n",
    "#regexpression to exclude features (F1..F25) from the list of parameters\n",
    "regex = re.compile('F[ 0-9]')\n",
    "\n",
    "for index, row in data_for_training.iterrows():\n",
    "    model='%s-%s'%(row['Model'],index)\n",
    "    print(model)\n",
    "    #if run was stopped because of a failed model, using data in AWS Sagemaker Experiment allows to fiter out what was run and what's not\n",
    "    #if len(trial_ds[trial_ds['DisplayName']=='bf-TrainingModels-%s'%(model)])>=1:\n",
    "    #    continue\n",
    "    #1. Verifying training and validation data exists (were created in preprocessing step or moved manually in a predefined location)\n",
    "\n",
    "    if not(s3.exists(row['Training_data']) & s3.exists(row['Validation_data'])):           \n",
    "        print('Training and Validation data do not exist. Skipping model %s'%(model))\n",
    "        print('Check Training data in %s'%row['Training_data'])\n",
    "        print('Check Validation data in %s'%row['Validation_data'])              \n",
    "        continue\n",
    "    #2. Do we have available instances slots to run the model? It depends on number of allowed in teh account simultaneously running specific instance types,\n",
    "    #number of instance type configured per model and configured number of model running\n",
    "    if CntRunningInst >= MaxNumOfRunningModels * training_instance_count: #not enough slots to add a model\n",
    "        print('There is no slot to train  %s model. Waiting...'%model)\n",
    "        #Waiting till a taining job complete\n",
    "        while CntRunningInst >= MaxNumOfRunningModels * training_instance_count:\n",
    "            print('.', end='')\n",
    "            time.sleep(check_training_job_every_sec)            \n",
    "            for p in processors:\n",
    "                ModelFailed=False\n",
    "                name=p.jobs[-1].describe()['TrainingJobName']\n",
    "                status=p.jobs[-1].describe()['TrainingJobStatus']\n",
    "                dummyFlag=not(StopOnFailedModel)\n",
    "                #job completed, failed or stopped (and do not stop the process) then we a slot is free\n",
    "                if (\n",
    "                    (status=='Completed') | \n",
    "                    ( ((status=='Failed') | \n",
    "                       (status=='Stopped')\n",
    "                      ) & \n",
    "                      dummyFlag\n",
    "                    )\n",
    "                   ):\n",
    "                    print('')\n",
    "                    print('Job %s  is %s'%(name,status))\n",
    "                    print('Continue training...')\n",
    "                    CntRunningInst = CntRunningInst - training_instance_count\n",
    "                    processors.remove(p)\n",
    "                    break\n",
    "                elif ( ((status=='Failed') | (status=='Stopped')) & StopOnFailedModel) :\n",
    "                    raise Exception('Model %s training failed!'%name)\n",
    "    #3. there is a slot to add a model training job\n",
    "    print('Creating training job for  %s model'%model)\n",
    "    #parameters\n",
    "    #techically early_stopping_rounds are not XGBoost parameters but it's an easy way to send them into the training/CV process\n",
    "    hyperparameters = {\n",
    "        'early_stopping_rounds':100,\n",
    "        'seed': 42,\n",
    "        'nfold': num_folds,\n",
    "        'GetFIFlg':GetFIFlg,\n",
    "        'GetTestScoreFlg':GetTestScoreFlg,\n",
    "        'GetTestPredFlg':GetTestPredFlg \n",
    "    } \n",
    "    for i, param in enumerate(data_for_training.columns):\n",
    "        #skip first column with Model name and dataset names or features\n",
    "        #if do not exclude then they will be added into experiment analytics as parameters but not used in training anyway\n",
    "        if ((param in ('Model','Training_data','Validation_data','Testing_data','Testing_labels')) | (bool(re.match(regex, param)))):\n",
    "            continue\n",
    "        hyperparameters[param] = row[param]\n",
    "    print(hyperparameters)\n",
    "    \n",
    "    #training and validation data from preprocessing\n",
    "    train_input = TrainingInput(row['Training_data'], content_type='text/csv')\n",
    "    validation_input = TrainingInput(row['Validation_data'], content_type='text/csv')\n",
    "    test_input = TrainingInput(row['Testing_data'], content_type='text/csv')\n",
    "    #Estimator\n",
    "\n",
    "    \n",
    "    training_job_name = model+'-'+time.strftime('%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "    xgb_script_mode_estimator = XGBoost(\n",
    "        entry_point=entry_point,\n",
    "        image_uri=image_uri,\n",
    "        hyperparameters=hyperparameters,\n",
    "        role=sagemaker_execution_role, \n",
    "        instance_count=training_instance_count,\n",
    "        instance_type=training_instance_type,\n",
    "        framework_version='1.2-1',\n",
    "        output_path='s3://%s/%s/'%(bucket,path_to_models),\n",
    "        metric_definitions=metric_definitions #only workds if image_uri is a custom container\n",
    "        )\n",
    "    \n",
    "    #Training\n",
    "    xgb_script_mode_estimator.fit({'train': train_input, 'validation': validation_input,'test':test_input}, job_name=training_job_name, wait=False,\n",
    "    experiment_config = {\n",
    "        'ExperimentName': Experiment_name ,\n",
    "        'TrialName' : Trial_name_training,\n",
    "        'TrialComponentDisplayName' : '%s-%s'%(Trial_name_training,model.replace('_','-')),}\n",
    "                                 )\n",
    "              \n",
    "    processors.append(xgb_script_mode_estimator)\n",
    "\n",
    "    CntRunningInst = CntRunningInst + training_instance_count\n",
    "    # to prevent throttling\n",
    "    time.sleep(.5)\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Training Jobs are Completed\n"
     ]
    }
   ],
   "source": [
    "#Waiting till the rest of the training jobs are complete\n",
    "eu.wait_training_jobs(processors=processors,check_every_sec=check_training_job_every_sec,print_every_n_output=12,wait_min=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment results\n",
    "\n",
    "Reading from AWS SageMaker experiment, saving to an experiment log file and visualization. The most complex part of the script below is to aggregate together the results of  all models trained on a different folds but for the same featureset and parameter set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wait till the data are updated in AWS experiment\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "#models training and validation data from experiment \n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=Experiment_name   \n",
    ")\n",
    "trial_comp_ds = trial_component_analytics.dataframe()\n",
    "trial_ds=trial_comp_ds[trial_comp_ds['DisplayName'].str.contains(Trial_name_training)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>GetFIFlg</th>\n",
       "      <th>GetTestPredFlg</th>\n",
       "      <th>GetTestScoreFlg</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>SageMaker.VolumeSizeInGB</th>\n",
       "      <th>...</th>\n",
       "      <th>validation - MediaType</th>\n",
       "      <th>validation - Value</th>\n",
       "      <th>SageMaker.DebugHookOutput - MediaType</th>\n",
       "      <th>SageMaker.DebugHookOutput - Value</th>\n",
       "      <th>SageMaker.ModelArtifact - MediaType</th>\n",
       "      <th>SageMaker.ModelArtifact - Value</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Experiments</th>\n",
       "      <th>Model</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>BaseModel-8-8-2021-05-30-04-02-11-aws-training...</td>\n",
       "      <td>FeatureSet-TrainingModels-BaseModel-8-8</td>\n",
       "      <td>arn:aws:sagemaker:us-west-2:757107622481:train...</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>757107622481.dkr.ecr.us-west-2.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.c5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/...</td>\n",
       "      <td>[FeatureSet-TrainingModels]</td>\n",
       "      <td>[FeatureSet]</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>BaseModel-3-3-2021-05-30-04-02-03-aws-training...</td>\n",
       "      <td>FeatureSet-TrainingModels-BaseModel-3-3</td>\n",
       "      <td>arn:aws:sagemaker:us-west-2:757107622481:train...</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>757107622481.dkr.ecr.us-west-2.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.c5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/...</td>\n",
       "      <td>[FeatureSet-TrainingModels]</td>\n",
       "      <td>[FeatureSet]</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>NoPlumbLeak-8-18-2021-05-30-04-02-30-aws-train...</td>\n",
       "      <td>FeatureSet-TrainingModels-NoPlumbLeak-8-18</td>\n",
       "      <td>arn:aws:sagemaker:us-west-2:757107622481:train...</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>757107622481.dkr.ecr.us-west-2.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.c5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/...</td>\n",
       "      <td>[FeatureSet-TrainingModels]</td>\n",
       "      <td>[FeatureSet]</td>\n",
       "      <td>NoPlumbLeak</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>NoPlumbLeak-3-13-2021-05-30-04-02-21-aws-train...</td>\n",
       "      <td>FeatureSet-TrainingModels-NoPlumbLeak-3-13</td>\n",
       "      <td>arn:aws:sagemaker:us-west-2:757107622481:train...</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>757107622481.dkr.ecr.us-west-2.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.c5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/...</td>\n",
       "      <td>[FeatureSet-TrainingModels]</td>\n",
       "      <td>[FeatureSet]</td>\n",
       "      <td>NoPlumbLeak</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Nocovalimit-3-23-2021-05-30-04-02-42-aws-train...</td>\n",
       "      <td>FeatureSet-TrainingModels-Nocovalimit-3-23</td>\n",
       "      <td>arn:aws:sagemaker:us-west-2:757107622481:train...</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>\"Y\"</td>\n",
       "      <td>757107622481.dkr.ecr.us-west-2.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.c5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>s3://kdproperty/Data/Experiments/FeatureSet/va...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://kdproperty/Models/Experiments/FeatureSet/...</td>\n",
       "      <td>[FeatureSet-TrainingModels]</td>\n",
       "      <td>[FeatureSet]</td>\n",
       "      <td>Nocovalimit</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   TrialComponentName  \\\n",
       "85  BaseModel-8-8-2021-05-30-04-02-11-aws-training...   \n",
       "86  BaseModel-3-3-2021-05-30-04-02-03-aws-training...   \n",
       "87  NoPlumbLeak-8-18-2021-05-30-04-02-30-aws-train...   \n",
       "88  NoPlumbLeak-3-13-2021-05-30-04-02-21-aws-train...   \n",
       "89  Nocovalimit-3-23-2021-05-30-04-02-42-aws-train...   \n",
       "\n",
       "                                   DisplayName  \\\n",
       "85     FeatureSet-TrainingModels-BaseModel-8-8   \n",
       "86     FeatureSet-TrainingModels-BaseModel-3-3   \n",
       "87  FeatureSet-TrainingModels-NoPlumbLeak-8-18   \n",
       "88  FeatureSet-TrainingModels-NoPlumbLeak-3-13   \n",
       "89  FeatureSet-TrainingModels-Nocovalimit-3-23   \n",
       "\n",
       "                                            SourceArn GetFIFlg GetTestPredFlg  \\\n",
       "85  arn:aws:sagemaker:us-west-2:757107622481:train...      \"Y\"            \"Y\"   \n",
       "86  arn:aws:sagemaker:us-west-2:757107622481:train...      \"Y\"            \"Y\"   \n",
       "87  arn:aws:sagemaker:us-west-2:757107622481:train...      \"Y\"            \"Y\"   \n",
       "88  arn:aws:sagemaker:us-west-2:757107622481:train...      \"Y\"            \"Y\"   \n",
       "89  arn:aws:sagemaker:us-west-2:757107622481:train...      \"Y\"            \"Y\"   \n",
       "\n",
       "   GetTestScoreFlg                                 SageMaker.ImageUri  \\\n",
       "85             \"Y\"  757107622481.dkr.ecr.us-west-2.amazonaws.com/s...   \n",
       "86             \"Y\"  757107622481.dkr.ecr.us-west-2.amazonaws.com/s...   \n",
       "87             \"Y\"  757107622481.dkr.ecr.us-west-2.amazonaws.com/s...   \n",
       "88             \"Y\"  757107622481.dkr.ecr.us-west-2.amazonaws.com/s...   \n",
       "89             \"Y\"  757107622481.dkr.ecr.us-west-2.amazonaws.com/s...   \n",
       "\n",
       "    SageMaker.InstanceCount SageMaker.InstanceType  SageMaker.VolumeSizeInGB  \\\n",
       "85                      1.0           ml.c5.xlarge                      30.0   \n",
       "86                      1.0           ml.c5.xlarge                      30.0   \n",
       "87                      1.0           ml.c5.xlarge                      30.0   \n",
       "88                      1.0           ml.c5.xlarge                      30.0   \n",
       "89                      1.0           ml.c5.xlarge                      30.0   \n",
       "\n",
       "    ... validation - MediaType  \\\n",
       "85  ...               text/csv   \n",
       "86  ...               text/csv   \n",
       "87  ...               text/csv   \n",
       "88  ...               text/csv   \n",
       "89  ...               text/csv   \n",
       "\n",
       "                                   validation - Value  \\\n",
       "85  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "86  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "87  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "88  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "89  s3://kdproperty/Data/Experiments/FeatureSet/va...   \n",
       "\n",
       "    SageMaker.DebugHookOutput - MediaType  \\\n",
       "85                                   None   \n",
       "86                                   None   \n",
       "87                                   None   \n",
       "88                                   None   \n",
       "89                                   None   \n",
       "\n",
       "                 SageMaker.DebugHookOutput - Value  \\\n",
       "85  s3://kdproperty/Models/Experiments/FeatureSet/   \n",
       "86  s3://kdproperty/Models/Experiments/FeatureSet/   \n",
       "87  s3://kdproperty/Models/Experiments/FeatureSet/   \n",
       "88  s3://kdproperty/Models/Experiments/FeatureSet/   \n",
       "89  s3://kdproperty/Models/Experiments/FeatureSet/   \n",
       "\n",
       "    SageMaker.ModelArtifact - MediaType  \\\n",
       "85                                 None   \n",
       "86                                 None   \n",
       "87                                 None   \n",
       "88                                 None   \n",
       "89                                 None   \n",
       "\n",
       "                      SageMaker.ModelArtifact - Value  \\\n",
       "85  s3://kdproperty/Models/Experiments/FeatureSet/...   \n",
       "86  s3://kdproperty/Models/Experiments/FeatureSet/...   \n",
       "87  s3://kdproperty/Models/Experiments/FeatureSet/...   \n",
       "88  s3://kdproperty/Models/Experiments/FeatureSet/...   \n",
       "89  s3://kdproperty/Models/Experiments/FeatureSet/...   \n",
       "\n",
       "                         Trials   Experiments        Model  ind  \n",
       "85  [FeatureSet-TrainingModels]  [FeatureSet]    BaseModel    8  \n",
       "86  [FeatureSet-TrainingModels]  [FeatureSet]    BaseModel    3  \n",
       "87  [FeatureSet-TrainingModels]  [FeatureSet]  NoPlumbLeak   18  \n",
       "88  [FeatureSet-TrainingModels]  [FeatureSet]  NoPlumbLeak   13  \n",
       "89  [FeatureSet-TrainingModels]  [FeatureSet]  Nocovalimit   23  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of models in the experiment is a combination of:\n",
    "# 1.featuresets (defined by Model name).\n",
    "# 2.folds (num_folds parameter)\n",
    "# 3.parameters sets (number of rows in model_params) \n",
    "# DisplayName in the experiment analytics is a combination of Model name, fold and line number(index) in data_for_training, \n",
    "# which is a combination of folds input data for specific datasets and parameters sets\n",
    "# index is a value after the last dash\n",
    "# fold is a value after one before last dash\n",
    "#The purpose of teh code below is to have in a separate columns Model name as in model_features and model_params, index of model_params and folds for each combinations\n",
    "# index is data_for_training can be converted to index in model_params via bining\n",
    "#we suppose to have the same number of folds for each set of features and parameters\n",
    "trial_ds['Model']=trial_ds['DisplayName'].str.replace(Trial_name_training+'-','')\n",
    "trial_ds['Model']=trial_ds['Model']#.str.replace('-','_')\n",
    "trial_ds['ind']=pd.to_numeric(trial_ds['Model'].apply(lambda x: x.rpartition('-')[2]))\n",
    "trial_ds['Model']=trial_ds['Model'].apply(lambda x: x.rpartition('-')[0])\n",
    "trial_ds['fold']=pd.to_numeric(trial_ds['Model'].apply(lambda x: x.rpartition('-')[2]))\n",
    "trial_ds['Model']=trial_ds['Model'].apply(lambda x: x.rpartition('-')[0])\n",
    "bin_labels=list()\n",
    "bins=len(model_params)\n",
    "for i in range(0,bins,1):\n",
    "    bin_labels.append(str(i))\n",
    "#number of columns with folds scores depends on the number of folds (num_folds) We do not know in advance how many of them exist in the results\n",
    "folds_columns=[]\n",
    "folds_train_columns=[]\n",
    "folds_test_columns=[]\n",
    "folds_valid_columns=[]\n",
    "folds_gain_columns=[]\n",
    "folds_weight_columns=[]\n",
    "folds_cover_columns=[]\n",
    "for i in range(0,int(num_folds),1):\n",
    "    folds_columns.append(str(i))\n",
    "    folds_train_columns.append('train-%s-fold'%i)\n",
    "    folds_valid_columns.append('valid-%s-fold'%i)\n",
    "    folds_test_columns.append('test-%s-fold'%i)\n",
    "    folds_gain_columns.append('gain-%s'%i)\n",
    "    folds_weight_columns.append('weight-%s'%i)\n",
    "    folds_cover_columns.append('cover-%s'%i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Best scores aggregated from folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ind</th>\n",
       "      <th>valid-0-fold</th>\n",
       "      <th>valid-1-fold</th>\n",
       "      <th>valid-2-fold</th>\n",
       "      <th>valid-3-fold</th>\n",
       "      <th>valid-4-fold</th>\n",
       "      <th>valid-5-fold</th>\n",
       "      <th>valid-6-fold</th>\n",
       "      <th>valid-7-fold</th>\n",
       "      <th>valid-8-fold</th>\n",
       "      <th>valid-9-fold</th>\n",
       "      <th>valid-gini-mean</th>\n",
       "      <th>valid-gini-std</th>\n",
       "      <th>valid-gini-sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>0.40443</td>\n",
       "      <td>0.35781</td>\n",
       "      <td>0.37166</td>\n",
       "      <td>0.40170</td>\n",
       "      <td>0.40248</td>\n",
       "      <td>0.38515</td>\n",
       "      <td>0.37313</td>\n",
       "      <td>0.37354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.383737</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>0.006180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35992</td>\n",
       "      <td>0.39159</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>0.022394</td>\n",
       "      <td>0.015835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoPipeFroze</td>\n",
       "      <td>8</td>\n",
       "      <td>0.37702</td>\n",
       "      <td>0.32724</td>\n",
       "      <td>0.34381</td>\n",
       "      <td>0.38137</td>\n",
       "      <td>0.37668</td>\n",
       "      <td>0.35745</td>\n",
       "      <td>0.34482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.358341</td>\n",
       "      <td>0.020727</td>\n",
       "      <td>0.007834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoPipeFroze</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32885</td>\n",
       "      <td>0.33897</td>\n",
       "      <td>0.37352</td>\n",
       "      <td>0.347113</td>\n",
       "      <td>0.023422</td>\n",
       "      <td>0.013523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoPlumbLeak</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40339</td>\n",
       "      <td>0.35520</td>\n",
       "      <td>0.37384</td>\n",
       "      <td>0.40365</td>\n",
       "      <td>0.40490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.388196</td>\n",
       "      <td>0.022603</td>\n",
       "      <td>0.010108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoPlumbLeak</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38139</td>\n",
       "      <td>0.37372</td>\n",
       "      <td>0.37049</td>\n",
       "      <td>0.35745</td>\n",
       "      <td>0.39270</td>\n",
       "      <td>0.375150</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoWaterRisk</td>\n",
       "      <td>5</td>\n",
       "      <td>0.38467</td>\n",
       "      <td>0.33901</td>\n",
       "      <td>0.35920</td>\n",
       "      <td>0.39104</td>\n",
       "      <td>0.38096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370976</td>\n",
       "      <td>0.021507</td>\n",
       "      <td>0.009618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NoWaterRisk</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.37432</td>\n",
       "      <td>0.35142</td>\n",
       "      <td>0.34369</td>\n",
       "      <td>0.34637</td>\n",
       "      <td>0.37934</td>\n",
       "      <td>0.359028</td>\n",
       "      <td>0.016581</td>\n",
       "      <td>0.007415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nocovalimit</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40125</td>\n",
       "      <td>0.34987</td>\n",
       "      <td>0.36678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.372633</td>\n",
       "      <td>0.026185</td>\n",
       "      <td>0.015118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nocovalimit</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40223</td>\n",
       "      <td>0.40114</td>\n",
       "      <td>0.37663</td>\n",
       "      <td>0.37322</td>\n",
       "      <td>0.36463</td>\n",
       "      <td>0.35659</td>\n",
       "      <td>0.38902</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.017618</td>\n",
       "      <td>0.006659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nolandlord</td>\n",
       "      <td>6</td>\n",
       "      <td>0.38713</td>\n",
       "      <td>0.34003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.363580</td>\n",
       "      <td>0.033305</td>\n",
       "      <td>0.023550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nolandlord</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35840</td>\n",
       "      <td>0.39127</td>\n",
       "      <td>0.38100</td>\n",
       "      <td>0.37308</td>\n",
       "      <td>0.34887</td>\n",
       "      <td>0.34394</td>\n",
       "      <td>0.34507</td>\n",
       "      <td>0.37850</td>\n",
       "      <td>0.365016</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.006462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nopool</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39692</td>\n",
       "      <td>0.34561</td>\n",
       "      <td>0.36727</td>\n",
       "      <td>0.40223</td>\n",
       "      <td>0.40132</td>\n",
       "      <td>0.37990</td>\n",
       "      <td>0.36924</td>\n",
       "      <td>0.36558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.020304</td>\n",
       "      <td>0.007178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nopool</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35433</td>\n",
       "      <td>0.39083</td>\n",
       "      <td>0.372580</td>\n",
       "      <td>0.025809</td>\n",
       "      <td>0.018250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Norplcostdwel</td>\n",
       "      <td>9</td>\n",
       "      <td>0.37578</td>\n",
       "      <td>0.32398</td>\n",
       "      <td>0.34543</td>\n",
       "      <td>0.38008</td>\n",
       "      <td>0.37575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.360204</td>\n",
       "      <td>0.024545</td>\n",
       "      <td>0.010977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Norplcostdwel</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35810</td>\n",
       "      <td>0.34077</td>\n",
       "      <td>0.32799</td>\n",
       "      <td>0.34101</td>\n",
       "      <td>0.37139</td>\n",
       "      <td>0.347852</td>\n",
       "      <td>0.016960</td>\n",
       "      <td>0.007585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nousagetype</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37397</td>\n",
       "      <td>0.31855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.346260</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.027710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nousagetype</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.33709</td>\n",
       "      <td>0.37521</td>\n",
       "      <td>0.36810</td>\n",
       "      <td>0.35266</td>\n",
       "      <td>0.33137</td>\n",
       "      <td>0.31900</td>\n",
       "      <td>0.33576</td>\n",
       "      <td>0.36320</td>\n",
       "      <td>0.347799</td>\n",
       "      <td>0.019940</td>\n",
       "      <td>0.007050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model ind  valid-0-fold  valid-1-fold  valid-2-fold  valid-3-fold  \\\n",
       "0       BaseModel   0       0.40443       0.35781       0.37166       0.40170   \n",
       "1       BaseModel   1           NaN           NaN           NaN           NaN   \n",
       "2     NoPipeFroze   8       0.37702       0.32724       0.34381       0.38137   \n",
       "3     NoPipeFroze   9           NaN           NaN           NaN           NaN   \n",
       "4     NoPlumbLeak   1       0.40339       0.35520       0.37384       0.40365   \n",
       "5     NoPlumbLeak   2           NaN           NaN           NaN           NaN   \n",
       "6     NoWaterRisk   5       0.38467       0.33901       0.35920       0.39104   \n",
       "7     NoWaterRisk   6           NaN           NaN           NaN           NaN   \n",
       "8     Nocovalimit   2       0.40125       0.34987       0.36678           NaN   \n",
       "9     Nocovalimit   3           NaN           NaN           NaN       0.40223   \n",
       "10     Nolandlord   6       0.38713       0.34003           NaN           NaN   \n",
       "11     Nolandlord   7           NaN           NaN       0.35840       0.39127   \n",
       "12         Nopool   4       0.39692       0.34561       0.36727       0.40223   \n",
       "13         Nopool   5           NaN           NaN           NaN           NaN   \n",
       "14  Norplcostdwel   9       0.37578       0.32398       0.34543       0.38008   \n",
       "15  Norplcostdwel  10           NaN           NaN           NaN           NaN   \n",
       "16    Nousagetype  10       0.37397       0.31855           NaN           NaN   \n",
       "17    Nousagetype  11           NaN           NaN       0.33709       0.37521   \n",
       "\n",
       "    valid-4-fold  valid-5-fold  valid-6-fold  valid-7-fold  valid-8-fold  \\\n",
       "0        0.40248       0.38515       0.37313       0.37354           NaN   \n",
       "1            NaN           NaN           NaN           NaN       0.35992   \n",
       "2        0.37668       0.35745       0.34482           NaN           NaN   \n",
       "3            NaN           NaN           NaN       0.32885       0.33897   \n",
       "4        0.40490           NaN           NaN           NaN           NaN   \n",
       "5            NaN       0.38139       0.37372       0.37049       0.35745   \n",
       "6        0.38096           NaN           NaN           NaN           NaN   \n",
       "7            NaN       0.37432       0.35142       0.34369       0.34637   \n",
       "8            NaN           NaN           NaN           NaN           NaN   \n",
       "9        0.40114       0.37663       0.37322       0.36463       0.35659   \n",
       "10           NaN           NaN           NaN           NaN           NaN   \n",
       "11       0.38100       0.37308       0.34887       0.34394       0.34507   \n",
       "12       0.40132       0.37990       0.36924       0.36558           NaN   \n",
       "13           NaN           NaN           NaN           NaN       0.35433   \n",
       "14       0.37575           NaN           NaN           NaN           NaN   \n",
       "15           NaN       0.35810       0.34077       0.32799       0.34101   \n",
       "16           NaN           NaN           NaN           NaN           NaN   \n",
       "17       0.36810       0.35266       0.33137       0.31900       0.33576   \n",
       "\n",
       "    valid-9-fold  valid-gini-mean  valid-gini-std  valid-gini-sem  \n",
       "0            NaN         0.383737        0.017479        0.006180  \n",
       "1        0.39159         0.375755        0.022394        0.015835  \n",
       "2            NaN         0.358341        0.020727        0.007834  \n",
       "3        0.37352         0.347113        0.023422        0.013523  \n",
       "4            NaN         0.388196        0.022603        0.010108  \n",
       "5        0.39270         0.375150        0.013077        0.005848  \n",
       "6            NaN         0.370976        0.021507        0.009618  \n",
       "7        0.37934         0.359028        0.016581        0.007415  \n",
       "8            NaN         0.372633        0.026185        0.015118  \n",
       "9        0.38902         0.380494        0.017618        0.006659  \n",
       "10           NaN         0.363580        0.033305        0.023550  \n",
       "11       0.37850         0.365016        0.018276        0.006462  \n",
       "12           NaN         0.378509        0.020304        0.007178  \n",
       "13       0.39083         0.372580        0.025809        0.018250  \n",
       "14           NaN         0.360204        0.024545        0.010977  \n",
       "15       0.37139         0.347852        0.016960        0.007585  \n",
       "16           NaN         0.346260        0.039188        0.027710  \n",
       "17       0.36320         0.347799        0.019940        0.007050  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation scores\n",
    "valid_ModelsResults = trial_ds[['Model','ind','fold','validation%s - Last'%('-'+score if score=='gini' else ':'+score)]].copy()\n",
    "valid_ModelsResults.columns=['Model','ind','fold','validation:%s'%score]\n",
    "valid_ModelsResults=valid_ModelsResults[['Model','fold','ind','validation:%s'%score]]\n",
    "valid_ModelsResults=valid_ModelsResults.sort_values(['Model','ind','fold'], ascending=[False,True,True])\n",
    "valid_ModelsResults['ind']=pd.cut(valid_ModelsResults['ind'],bins=bins,labels=bin_labels)\n",
    "valid_ModelsResults = pd.pivot_table(valid_ModelsResults, index=['Model','ind'], columns=['fold'])\n",
    "valid_ModelsResults.reset_index( drop=False, inplace=True )\n",
    "valid_ModelsResults.columns = valid_ModelsResults.columns.droplevel(0)\n",
    "valid_ModelsResults.columns =['Model','ind']+folds_valid_columns\n",
    "valid_ModelsResults['valid-%s-mean'%score]=valid_ModelsResults[folds_valid_columns].mean(axis=1)\n",
    "valid_ModelsResults['valid-%s-std'%score]=valid_ModelsResults[folds_valid_columns].std(axis=1)\n",
    "valid_ModelsResults['valid-%s-sem'%score]=valid_ModelsResults[folds_valid_columns].sem(axis=1)\n",
    "valid_ModelsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ModelsResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training scores\n",
    "train_ModelsResults = trial_ds[['Model','ind','fold','train%s - Last'%('-'+score if score=='gini' else ':'+score)]].copy()\n",
    "train_ModelsResults.columns=['Model','ind','fold','train:%s'%score]\n",
    "train_ModelsResults=train_ModelsResults[['Model','fold','ind','train:%s'%score]]\n",
    "train_ModelsResults=train_ModelsResults.sort_values(['Model','ind','fold'], ascending=[False,True,True])\n",
    "train_ModelsResults['ind']=pd.cut(train_ModelsResults['ind'],bins=bins,labels=bin_labels)\n",
    "train_ModelsResults = pd.pivot_table(train_ModelsResults, index=['Model','ind'], columns=['fold'])\n",
    "train_ModelsResults.reset_index( drop=False, inplace=True )\n",
    "train_ModelsResults.columns = train_ModelsResults.columns.droplevel(0)\n",
    "train_ModelsResults.columns =['Model','ind']+folds_train_columns\n",
    "train_ModelsResults['train-%s-mean'%score]=train_ModelsResults[folds_train_columns].mean(axis=1)\n",
    "train_ModelsResults['train-%s-std'%score]=train_ModelsResults[folds_train_columns].std(axis=1)\n",
    "train_ModelsResults['train-%s-sem'%score]=train_ModelsResults[folds_train_columns].sem(axis=1)\n",
    "train_ModelsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All together\n",
    "BestResults = pd.merge(train_ModelsResults, valid_ModelsResults, on=['Model','ind'], how='inner')\n",
    "BestResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional info not registered in AWS Sage Maker experiment\n",
    "#but saved in csv files in output folder from training\n",
    "#1.Feature Importance\n",
    "#2.Test Scores\n",
    "#3.Prediction\n",
    "#4.Training output (evaluation results)\n",
    "ModelEvalResults=pd.DataFrame()\n",
    "FI = pd.DataFrame()\n",
    "ModelsTestScores = pd.DataFrame()\n",
    "for index, row in trial_ds.iterrows():\n",
    "    model=row['Model']\n",
    "    fold=int(row['fold'])\n",
    "    ind=int(row['ind'])\n",
    "    print('%s-%s-%s'%(model,fold,index))\n",
    "    eval_results_file=row['SageMaker.ModelArtifact - Value'].replace('model.tar.gz','output.tar.gz').replace('s3://%s/'%bucket,'')\n",
    "    print(eval_results_file)\n",
    "    if s3.exists(row['SageMaker.ModelArtifact - Value'].replace('model.tar.gz','output.tar.gz')):\n",
    "        sagemaker_session.download_data(path=temp_folder, bucket=bucket, key_prefix=eval_results_file)\n",
    "        print('Processing...')\n",
    "        eval_results_file=os.path.join(temp_folder, 'output.tar.gz')\n",
    "        with tarfile.open(eval_results_file) as tar:\n",
    "            tar.extractall(path=temp_folder)\n",
    "        eval_results_file=os.path.join(temp_folder, 'eval_results.csv')\n",
    "        eval_results=pd.read_csv(eval_results_file, error_bad_lines=False, index_col=False)\n",
    "        eval_results['Model']=model\n",
    "        eval_results['fold']=fold\n",
    "        eval_results['ind']=ind\n",
    "        ModelEvalResults = pd.concat([ModelEvalResults,eval_results])\n",
    "        #FI\n",
    "        if (GetFIFlg=='Y'):\n",
    "            fi_model_file=os.path.join(temp_folder, 'fi.csv')     \n",
    "            if  (os.path.isfile(fi_model_file)):\n",
    "                    fi_model=pd.read_csv(fi_model_file, error_bad_lines=False, index_col=False)\n",
    "                    fi_model['feature']=fi_model['feature'].map(GetMap(model))\n",
    "                    fi_model['Model']=model\n",
    "                    fi_model['fold']=fold\n",
    "                    fi_model['ind']=ind     \n",
    "                    FI = pd.concat([FI,fi_model])           \n",
    "        #Test Scores \n",
    "        if (GetTestScoreFlg=='Y'):\n",
    "            test_score_file=os.path.join(temp_folder, 'test_score.csv')\n",
    "            if (os.path.isfile(test_score_file)):\n",
    "                test_score=pd.read_csv(test_score_file, error_bad_lines=False, index_col=False)\n",
    "                test_score['Model']=model\n",
    "                test_score['fold']=fold\n",
    "                test_score['ind']=ind \n",
    "                ModelsTestScores = pd.concat([ModelsTestScores,test_score])       \n",
    "    else:\n",
    "        print('File does not exist')       \n",
    "ModelEvalResults=ModelEvalResults[['Model','fold','ind','train','valid']]  \n",
    "if (GetFIFlg=='Y'):\n",
    "    FI=FI[['Model','fold','ind','feature','gain','weight','cover']]\n",
    "if (GetTestScoreFlg=='Y'):\n",
    "    ModelsTestScores=ModelsTestScores[['Model','fold','ind','roc-auc-test' if score=='auc' and entry_point!='ModelTraining_Gini_named_AUC_EvalMetric.py' else 'gini-test']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Test dataset Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting Test Scores (original structure has each fold in a row) and averaging\n",
    "if len(ModelsTestScores)>0:\n",
    "    ModelsTestScores=ModelsTestScores.sort_values(['Model','ind','fold'], ascending=[False,True,True])\n",
    "    ModelsTestScores['ind']=pd.cut(ModelsTestScores['ind'],bins=bins,labels=bin_labels)\n",
    "    ModelsTestScores['ind']=ModelsTestScores['ind'].astype(int)\n",
    "    ModelsTestScores = pd.pivot_table(ModelsTestScores, index=['Model','ind'], columns=['fold'])\n",
    "    ModelsTestScores.reset_index( drop=False, inplace=True )\n",
    "    ModelsTestScores.columns = ModelsTestScores.columns.droplevel(0)\n",
    "    ModelsTestScores.columns =['Model','ind']+folds_test_columns\n",
    "    ModelsTestScores['test-%s-mean'%score]=ModelsTestScores[folds_test_columns].mean(axis=1)\n",
    "    ModelsTestScores['test-%s-std'%score]=ModelsTestScores[folds_test_columns].std(axis=1)\n",
    "    ModelsTestScores['test-%s-sem'%score]=ModelsTestScores[folds_test_columns].sem(axis=1)\n",
    "    #Saving into the Experiment log file models results\n",
    "    eu.SaveToExperimentLog(Experiments_file, '%s TestScores'%Experiment_name, ModelsTestScores)\n",
    "    print(ModelsTestScores)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting Feature Importance (original structure has each fold in a row) and averaging\n",
    "if len(FI)>0:\n",
    "    FI_gain=FI[['Model','ind','fold','feature','gain']]\n",
    "    FI_gain=FI_gain.sort_values(['Model','ind','fold'], ascending=[False,True,True])\n",
    "    FI_gain['ind']=pd.cut(pd.to_numeric(FI_gain['ind']),bins=bins,labels=bin_labels)\n",
    "    FI_gain = pd.pivot_table(FI_gain, index=['Model','ind','feature'], columns=['fold'])\n",
    "    FI_gain.reset_index( drop=False, inplace=True )\n",
    "    FI_gain.columns = FI_gain.columns.droplevel(0)\n",
    "    FI_gain.columns =['Model','ind','feature']+folds_gain_columns\n",
    "    FI_gain['gain-mean']=FI_gain[folds_gain_columns].mean(axis=1)\n",
    "    FI_gain['gainc-std']=FI_gain[folds_gain_columns].std(axis=1)\n",
    "    FI_gain['gain-sem']=FI_gain[folds_gain_columns].sem(axis=1)\n",
    "    #\n",
    "    FI_weight=FI[['Model','ind','fold','feature','weight']]\n",
    "    FI_weight=FI_weight.sort_values(['Model','ind','fold'], ascending=[False,True,True])\n",
    "    FI_weight['ind']=pd.cut(pd.to_numeric(FI_weight['ind']),bins=bins,labels=bin_labels)\n",
    "    FI_weight = pd.pivot_table(FI_weight, index=['Model','ind','feature'], columns=['fold'])\n",
    "    FI_weight.reset_index( drop=False, inplace=True )\n",
    "    FI_weight.columns = FI_weight.columns.droplevel(0)\n",
    "    FI_weight.columns =['Model','ind','feature']+folds_weight_columns\n",
    "    FI_weight['weight-mean']=FI_weight[folds_weight_columns].mean(axis=1)\n",
    "    FI_weight['weightc-std']=FI_weight[folds_weight_columns].std(axis=1)\n",
    "    FI_weight['weight-sem']=FI_weight[folds_weight_columns].sem(axis=1)   \n",
    "    #\n",
    "    FI_cover=FI[['Model','ind','fold','feature','cover']]\n",
    "    FI_cover=FI_cover.sort_values(['Model','ind','fold'], ascending=[False,True,True])\n",
    "    FI_cover['ind']=pd.cut(pd.to_numeric(FI_cover['ind']),bins=bins,labels=bin_labels)\n",
    "    FI_cover = pd.pivot_table(FI_cover, index=['Model','ind','feature'], columns=['fold'])\n",
    "    FI_cover.reset_index( drop=False, inplace=True )\n",
    "    FI_cover.columns = FI_cover.columns.droplevel(0)\n",
    "    FI_cover.columns =['Model','ind','feature']+folds_cover_columns\n",
    "    FI_cover['cover-mean']=FI_cover[folds_cover_columns].mean(axis=1)\n",
    "    FI_cover['coverc-std']=FI_cover[folds_cover_columns].std(axis=1)\n",
    "    FI_cover['cover-sem']=FI_cover[folds_cover_columns].sem(axis=1) \n",
    "    FI=pd.merge(FI_gain, FI_weight, on=['Model','ind','feature'], how='inner')\n",
    "    FI=pd.merge(FI, FI_cover, on=['Model','ind','feature'], how='inner')\n",
    "    FI['ind']=pd.to_numeric(FI['ind'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3a.Visualization Feature Importance from cross validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(FI):\n",
    "    lst_chart_filenames = list()    \n",
    "    for index, row in model_params.iterrows():\n",
    "        if len(FI[( (FI['Model']==row['Model']) & (FI['ind']==index))])>0:\n",
    "            data=FI[( (FI['Model']==row['Model']) & (FI['ind']==index))].sort_values('gain-mean',ascending=False)\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=3,figsize=(20,5)) \n",
    "            fig.suptitle('%s %s'%(row['Model'],index))\n",
    "            fig.subplots_adjust(bottom=0.5)\n",
    "            \n",
    "            ax = axs[0]\n",
    "            ax.errorbar(data['feature'], data['gain-mean'], color = 'blue',  ecolor='lightgray', elinewidth=3, capsize=0,yerr=data['gain-sem'], fmt='o')\n",
    "            ax.set_title('Gain')\n",
    "            ax.set_xticklabels(data['feature'].values,rotation=90)\n",
    "            ax.grid(axis='both')\n",
    " \n",
    "            data=data.sort_values('weight-mean',ascending=False)\n",
    "            ax = axs[1]\n",
    "            ax.errorbar(data['feature'], data['weight-mean'], color = 'blue',  ecolor='lightgray', elinewidth=3, capsize=0,yerr=data['weight-sem'], fmt='o')\n",
    "            ax.set_title('Weight')\n",
    "            ax.set_xticklabels(data['feature'].values,rotation=90)\n",
    "            ax.grid(axis='both')\n",
    "                         \n",
    "            data=data.sort_values('cover-mean',ascending=False)\n",
    "            ax = axs[2]\n",
    "            ax.errorbar(data['feature'], data['cover-mean'], color = 'blue',  ecolor='lightgray', elinewidth=3, capsize=0,yerr=data['weight-sem'], fmt='o')\n",
    "            ax.set_title('Cover')\n",
    "            ax.set_xticklabels(data['feature'].values,rotation=90)\n",
    "            ax.grid(axis='both')\n",
    "            \n",
    "            chart_filename=temp_folder+'%s %s.png'%(row['Model'],index)\n",
    "            lst_chart_filenames.append(chart_filename)\n",
    "            fig.savefig(chart_filename,format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(FI): \n",
    "    #Saving into the Experiment log file models results\n",
    "    eu.SaveToExperimentLog(Experiments_file, '%s FI'%Experiment_name, FI)\n",
    "    eu.SaveChartToExperimentLog(Experiments_file, '%s FI'%Experiment_name, len(FI), 20, lst_chart_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Training and validation errors from folds: averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting and averaging evaluation results by fold\n",
    "CVResults=ModelEvalResults.copy()\n",
    "CVResults['ind']=pd.to_numeric(pd.cut(CVResults['ind'],bins=bins,labels=bin_labels))\n",
    "CVResults['index'] = CVResults.index\n",
    "CVResults = pd.pivot_table(CVResults, index=['index','Model','ind'], columns=['fold'])\n",
    "#folds for teh same parameters and features can have different length of training\n",
    "CVResults = CVResults.dropna()\n",
    "CVResults.reset_index( drop=False, inplace=True )\n",
    "CVResults.columns = CVResults.columns.droplevel(0)\n",
    "CVResults.columns =['index','Model','ind']+folds_train_columns+folds_valid_columns\n",
    "CVResults = CVResults.drop('index', axis=1)\n",
    "CVResults['train-%s-mean'%score]=CVResults[folds_train_columns].mean(axis=1)\n",
    "CVResults['train-%s-std'%score]=CVResults[folds_train_columns].std(axis=1)\n",
    "CVResults['train-%s-sem'%score]=CVResults[folds_train_columns].sem(axis=1)\n",
    "\n",
    "CVResults['valid-%s-mean'%score]=CVResults[folds_valid_columns].mean(axis=1)\n",
    "CVResults['valid-%s-std'%score]=CVResults[folds_valid_columns].std(axis=1)\n",
    "CVResults['valid-%s-sem'%score]=CVResults[folds_valid_columns].sem(axis=1)\n",
    "CVResults = CVResults.drop(folds_valid_columns, axis=1)\n",
    "CVResults = CVResults.drop(folds_train_columns, axis=1)\n",
    "CVResults.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Visualization aggregated from folds model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluding from chart models which did not learn anything (0.5 is random guessing)\n",
    "#data = BestResults[BestResults['valid-%s-mean'%score]>0.5].copy()\n",
    "#if len(ModelsTestScores)>0:\n",
    "#    data_test = ModelsTestScores[ModelsTestScores['test-%s-mean'%score]>0.5].copy()\n",
    "\n",
    "data = BestResults.copy()\n",
    "if len(ModelsTestScores)>0:\n",
    "    data_test = ModelsTestScores.copy()   \n",
    "    \n",
    "#list of models for xticks\n",
    "data['xticks']=data['Model']+' '+data['ind'].astype(str) \n",
    "xticks=data['xticks'].unique().tolist()\n",
    "\n",
    "\n",
    "# The x position \n",
    "r1 = np.arange(len(data))\n",
    "if len(ModelsTestScores)>0:\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=1, sharex=True,figsize=(20,10))\n",
    "else:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True,figsize=(20,10))\n",
    "ax = axs[0]\n",
    "ax.errorbar(r1, data['valid-%s-mean'%score], color = 'cyan',  ecolor='lightgray', elinewidth=3, capsize=0,yerr=data['valid-%s-sem'%score], fmt='o')\n",
    "ax.set_title('valid-%s-mean'%score)\n",
    "ax.grid(axis='both')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.errorbar(r1, data['train-%s-mean'%score],  color = 'blue',  ecolor='lightgray', elinewidth=3,capsize=0, yerr=data['train-%s-sem'%score],  fmt='o')\n",
    "ax.set_title('train-%s-mean'%score)\n",
    "ax.set_xticks([r  for r in range(len(data))])\n",
    "ax.set_xticklabels(xticks,rotation=90)\n",
    "ax.grid(axis='both')\n",
    "fig.suptitle('Means of %s with standard error of the mean'%score)\n",
    "if len(data_test)>0:\n",
    "    ax = axs[2]\n",
    "    ax.errorbar(r1, data_test['test-%s-mean'%score],  color = 'green',  ecolor='lightgray', elinewidth=3,capsize=0, yerr=data_test['test-%s-sem'%score],  fmt='o')\n",
    "    ax.set_title('test-%s-mean'%score)\n",
    "    ax.set_xticks([r  for r in range(len(data_test))])\n",
    "    ax.set_xticklabels(xticks,rotation=90)\n",
    "    ax.grid(axis='both')\n",
    "    \n",
    "lst_model_scores_chart_filenames=list()\n",
    "chart_filename=temp_folder+'Models Scores.png'\n",
    "lst_model_scores_chart_filenames.append(chart_filename)\n",
    "fig.savefig(chart_filename,format='png')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Corrected t-test compares VALIDATION scores of individual folds in a choosen model to the rest of the models folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a specific BaseModel name and index or just select with min or max score\n",
    "#The rest of the models will be compared to baseModel and baseind\n",
    "BaseModel='BaseModel'\n",
    "BaseInd='0'\n",
    "#BaseModel=BestResults[BestResults['valid-%s-mean'%score]==BestResults['valid-%s-mean'%score].max()]['Model'].values[0]\n",
    "#BaseInd=BestResults[BestResults['valid-%s-mean'%score]==BestResults['valid-%s-mean'%score].max()]['ind'].values[0]\n",
    "BaseModelResults=BestResults[((BestResults['Model']==BaseModel) & (BestResults['ind']==BaseInd))][folds_valid_columns].values[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrected t-test for each record in BestResults\n",
    "for index, model in BestResults.iterrows():\n",
    "    if ((model['Model']!=BaseModel) | (model['ind']!=BaseInd)):\n",
    "        AnalyzedModelResults=model[folds_valid_columns].values.tolist()\n",
    "        (t, critical_value, pvalue) = eu.corrected_paired_ttest(BaseModelResults,AnalyzedModelResults, n1, n2, alpha)\n",
    "        BestResults.at[index,'corrected t-statistic']= t\n",
    "        BestResults.at[index,'corrected pvalue'] = pvalue \n",
    "        if pvalue>=alpha:\n",
    "            BestResults.at[index,'corrected t-test Comment'] = 'No difference with %s with %s significance level'%(BaseModel,alpha)\n",
    "        else:\n",
    "            BestResults.at[index,'corrected t-test Comment'] = 'There is a difference with %s with %s significance level'%(BaseModel,alpha)\n",
    "BestResults[['Model','ind','valid-%s-mean'%score,'corrected t-statistic','corrected pvalue','corrected t-test Comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining the results of the experiment with the experiment configuration\n",
    "BestResults = pd.concat([BestResults, model_params.drop('Model',axis=1)], axis=1)\n",
    "BestResults = pd.merge(BestResults, model_features, on=['Model'], how='inner')\n",
    "BestResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Corrected Confidence interval of the difference between model VALIDATION scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_name = list()\n",
    "CI_mean = list()\n",
    "CI_lower = list()\n",
    "CI_upper = list()\n",
    "for index, model in BestResults.iterrows():\n",
    "    if ((model['Model']!=BaseModel) | (model['ind']!=BaseInd)):\n",
    "        AnalyzedModelResults=model[folds_valid_columns].values.tolist()\n",
    "        diff=[np.abs(y - x) for y, x in zip(BaseModelResults,AnalyzedModelResults)]\n",
    "        CI=eu.corrected_confidence_interval(BaseModelResults,AnalyzedModelResults, n1, n2, 1-alpha)\n",
    "        CI_name.append(model['Model']+' '+str(model['ind']))\n",
    "        CI_mean.append(np.mean(diff))\n",
    "        CI_lower.append(CI[0])\n",
    "        CI_upper.append(CI[1])          \n",
    "        BestResults.at[index,'BaseModel Diff mean'] = np.mean(diff)\n",
    "        BestResults.at[index,'BaseModel Corrected CI lower'] = CI[0]\n",
    "        BestResults.at[index,'BaseModel Corrected CI upper'] = CI[1]\n",
    "CI_df = pd.DataFrame(list(zip(CI_name, CI_mean, CI_lower, CI_upper)), columns=['Model','mean','lower','upper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=np.arange(0,CI_df['upper'].max() + CI_df['upper'].max()/10,CI_df['upper'].max()/10)\n",
    "plt.figure(figsize=(20,10))\n",
    "for lower,mean,upper,x in zip(CI_df['lower'],CI_df['mean'],CI_df['upper'],range(len(CI_df))):\n",
    "    plt.plot((x,x),(lower,upper),'r_-',markersize=20,color='blue')\n",
    "    plt.plot(x,mean,'ro',color='red')\n",
    "plt.xticks(range(len(CI_df)),list(CI_df['Model']),rotation=90)\n",
    "plt.yticks(dim)\n",
    "plt.grid(axis='both')\n",
    "\n",
    "#plt.margins(x=2)\n",
    "_=plt.title('Correcetd Confidence Interval of validation scores differences')\n",
    "lst_chart_filenames=list()\n",
    "chart_filename=temp_folder+'Correcetd Confidence Interval of validation scores differences.png'\n",
    "lst_chart_filenames.append(chart_filename)\n",
    "\n",
    "plt.savefig(chart_filename,format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Students t-test compares VALIDATION scores of individual folds in a choosen model to the rest of the models folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-test for each record in BestResults\n",
    "for index, model in BestResults.iterrows():\n",
    "    if ((model['Model']!=BaseModel) | (model['ind']!=BaseInd)):\n",
    "        AnalyzedModelResults=model[folds_valid_columns].values.tolist()\n",
    "        t=stats.ttest_rel(BaseModelResults,AnalyzedModelResults)\n",
    "        BestResults.at[index,'t-statistic']= t.statistic\n",
    "        BestResults.at[index,'pvalue'] = t.pvalue \n",
    "        if t.pvalue>=alpha:\n",
    "            BestResults.at[index,'t-test Comment'] = 'No difference with %s with %s alpha'%(BaseModel,alpha)\n",
    "        else:\n",
    "            BestResults.at[index,'t-test Comment'] = 'There is a difference with %s with %s alpha'%(BaseModel,alpha)\n",
    "BestResults[['Model','ind','valid-%s-mean'%score,'t-statistic','pvalue','t-test Comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Confidence interval of the difference between model Validation  scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_name = list()\n",
    "CI_mean = list()\n",
    "CI_lower = list()\n",
    "CI_upper = list()\n",
    "for index, model in BestResults.iterrows():\n",
    "    if ((model['Model']!=BaseModel) | (model['ind']!=BaseInd)):\n",
    "        AnalyzedModelResults=model[folds_valid_columns].values.tolist()\n",
    "        diff=[np.abs(y - x) for y, x in zip(BaseModelResults,AnalyzedModelResults)]\n",
    "        CI=stats.t.interval(1-alpha, len(diff)-1, loc=np.mean(diff), scale=stats.sem(diff))\n",
    "        CI_name.append(model['Model']+' '+str(model['ind']))\n",
    "        CI_mean.append(np.mean(diff))\n",
    "        CI_lower.append(CI[0])\n",
    "        CI_upper.append(CI[1])          \n",
    "        BestResults.at[index,'BaseModel Diff mean'] = np.mean(diff)\n",
    "        BestResults.at[index,'BaseModel Corrected CI lower'] = CI[0]\n",
    "        BestResults.at[index,'BaseModel Corrected CI upper'] = CI[1]\n",
    "CI_df = pd.DataFrame(list(zip(CI_name, CI_mean, CI_lower, CI_upper)), columns=['Model','mean','lower','upper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=np.arange(0,CI_df['upper'].max() + CI_df['upper'].max()/10,CI_df['upper'].max()/10)\n",
    "plt.figure(figsize=(20,10))\n",
    "for lower,mean,upper,x in zip(CI_df['lower'],CI_df['mean'],CI_df['upper'],range(len(CI_df))):\n",
    "    plt.plot((x,x),(lower,upper),'r_-',markersize=20,color='blue')\n",
    "    plt.plot(x,mean,'ro',color='red')\n",
    "plt.xticks(range(len(CI_df)),list(CI_df['Model']),rotation=90)\n",
    "plt.yticks(dim)\n",
    "plt.grid(axis='both')\n",
    "\n",
    "#plt.margins(x=2)\n",
    "_=plt.title('Confidence Interval of validation scores differences')\n",
    "chart_filename=temp_folder+'Confidence Interval of validation scores differences.png'\n",
    "lst_chart_filenames.append(chart_filename)\n",
    "\n",
    "plt.savefig(chart_filename,format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving into the Experiment log file models results\n",
    "eu.SaveToExperimentLog(Experiments_file, '%s BestResults'%Experiment_name, BestResults)\n",
    "eu.SaveChartToExperimentLog(Experiments_file, '%s BestResults'%Experiment_name, len(BestResults), 40, lst_chart_filenames)\n",
    "eu.SaveChartToExperimentLog(Experiments_file, '%s BestResults'%Experiment_name, len(BestResults)+100, 40, lst_model_scores_chart_filenames) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. t-test compares TEST scores of individual folds in a choosen model to the rest of the models folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a specific BaseModel name and index or just select with min or max score\n",
    "#The rest of the models will be compared to baseModel and baseind\n",
    "if len(ModelsTestScores)>0:\n",
    "    #BaseModel=ModelTestScores[ModelTestScores['mean']==ModelTestScores['mean'].max()]['Model'].values[0]\n",
    "    #BaseInd=ModelTestScores[ModelTestScores['mean']==ModelTestScores['mean'].max()]['ind'].values[0]\n",
    "    BaseModel='BaseModel'\n",
    "    BaseInd=0\n",
    "    BaseModelResults=ModelsTestScores[((ModelsTestScores['Model']==BaseModel) & (ModelsTestScores['ind']==BaseInd))][folds_test_columns].values[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-test for each record in BestResults\n",
    "if len(ModelsTestScores)>0:\n",
    "    for index, model in ModelsTestScores.iterrows():\n",
    "        if ((model['Model']!=BaseModel) | (model['ind']!=BaseInd)):\n",
    "            AnalyzedModelResults=model[folds_test_columns].values.tolist()\n",
    "            t=stats.ttest_rel(BaseModelResults,AnalyzedModelResults)\n",
    "            ModelsTestScores.at[index,'t-statistic']= t.statistic\n",
    "            ModelsTestScores.at[index,'pvalue'] = t.pvalue \n",
    "            if t.pvalue>=alpha:\n",
    "                ModelsTestScores.at[index,'Comment'] = 'No difference with %s with %s significance level'%(BaseModel,alpha)\n",
    "            else:\n",
    "                ModelsTestScores.at[index,'Comment'] = 'There is a difference with %s with %s significance level'%(BaseModel,alpha)\n",
    "    print(ModelsTestScores[['Model','ind','test-%s-mean'%score,'t-statistic','pvalue','Comment']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Confidence interval of the difference between model TEST scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ModelsTestScores)>0:\n",
    "    CI_name = list()\n",
    "    CI_mean = list()\n",
    "    CI_lower = list()\n",
    "    CI_upper = list()\n",
    "    for index, model in ModelsTestScores.iterrows():\n",
    "        if ((model['Model']!=BaseModel) | (model['ind']!=BaseInd)):\n",
    "            AnalyzedModelResults=model[folds_test_columns].values.tolist()\n",
    "            diff=[np.abs(y - x) for y, x in zip(BaseModelResults,AnalyzedModelResults)]\n",
    "            CI=stats.t.interval(1-alpha, len(diff)-1, loc=np.mean(diff), scale=stats.sem(diff))\n",
    "            CI_name.append(model['Model']+' '+str(model['ind']) )\n",
    "            CI_mean.append(np.mean(diff))\n",
    "            CI_lower.append(CI[0])\n",
    "            CI_upper.append(CI[1])  \n",
    "            ModelsTestScores.at[index,'BaseModel Diff mean'] = np.mean(diff)\n",
    "            ModelsTestScores.at[index,'BaseModel Corrected CI lower'] = CI[0]\n",
    "            ModelsTestScores.at[index,'BaseModel Corrected CI upper'] = CI[1]                       \n",
    "    CI_df = pd.DataFrame(list(zip(CI_name, CI_mean, CI_lower, CI_upper)), columns=['Model','mean','lower','upper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ModelsTestScores)>0:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    dim=np.arange(0,CI_df['upper'].max() + CI_df['upper'].max()/10,CI_df['upper'].max()/10)\n",
    "    for lower,mean,upper,x in zip(CI_df['lower'],CI_df['mean'],CI_df['upper'],range(len(CI_df))):\n",
    "        plt.plot((x,x),(lower,upper),'r_-',markersize=20,color='blue')\n",
    "        plt.plot(x,mean,'ro',color='red')\n",
    "    plt.xticks(range(len(CI_df)),list(CI_df['Model']),rotation=90)\n",
    "    plt.yticks(dim)\n",
    "    plt.grid(axis='both')\n",
    "    #plt.margins(x=2)\n",
    "    _=plt.title('Confidence Interval of test scores differences')\n",
    "    lst_chart_filenames=list()\n",
    "    chart_filename=temp_folder+'Confidence Interval of test scores differences.png'\n",
    "    lst_chart_filenames.append(chart_filename)\n",
    "    plt.savefig(chart_filename,format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the means of model scores for the entire population present in this confidence interval. If there is no difference, then the interval contains zero (0). If zero is NOT in the range of values, the difference is statistically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ModelsTestScores)>0:\n",
    "    #Saving into the Experiment log file models results\n",
    "    eu.SaveToExperimentLog(Experiments_file, '%s TestScores'%Experiment_name, ModelsTestScores)\n",
    "    eu.SaveChartToExperimentLog(Experiments_file, '%s TestScores'%Experiment_name, len(ModelsTestScores), 20, lst_chart_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Training and validation errors (output from the model) to estimate overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_chart_filenames=list()\n",
    "for index, row in model_params.iterrows():\n",
    "    if len(CVResults[( (CVResults['Model']==row['Model']) & (CVResults['ind']==index))])>0:\n",
    "        data=CVResults[( (CVResults['Model']==row['Model']) & (CVResults['ind']==index))]\n",
    "        ax=data[['train-%s-mean'%score,'valid-%s-mean'%score]].plot(title=row['Model']+'-'+str(index))\n",
    "        ax.fill_between(data.index.values, (data['train-%s-mean'%score].values-data['train-%s-sem'%score].values), (data['train-%s-mean'%score].values + data['train-%s-sem'%score].values), color='b', alpha=.1)\n",
    "        ax.fill_between(data.index.values, (data['valid-%s-mean'%score].values-data['valid-%s-sem'%score].values), (data['valid-%s-mean'%score].values + data['valid-%s-sem'%score].values), color='r', alpha=.1)\n",
    "        chart_filename=temp_folder+'train-valid scores %s-%s.png'%(row['Model'],index)\n",
    "        lst_chart_filenames.append(chart_filename)        \n",
    "        ax.figure.savefig(chart_filename,format='png')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving into the Experiment log file models results\n",
    "eu.SaveToExperimentLog(Experiments_file, '%s CVResults'%Experiment_name, CVResults.tail(10))\n",
    "eu.SaveChartToExperimentLog(Experiments_file, '%s CVResults'%Experiment_name, 10, 20, lst_chart_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving models artifacts into the Experiment Log file\n",
    "ModelsFiles=trial_ds[['Model','fold','ind','SageMaker.ModelArtifact - Value']]\n",
    "ModelsFiles.columns=['Model','fold','ind','ModelFile']\n",
    "ModelsFiles=ModelsFiles.sort_values(['Model','ind','fold'], ascending=[False,True,True])\n",
    "ModelsFiles['ind']=pd.cut(ModelsFiles['ind'],bins=bins,labels=bin_labels)\n",
    "eu.SaveToExperimentLog(Experiments_file, '%s ModelFiles'%Experiment_name, ModelsFiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
